{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Machine Learning | Hand Motion Recognition Project</title>
  <link rel="stylesheet" href="{% static 'main_app/css/style.css' %}">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css" rel="stylesheet">
  <link href="https://unpkg.com/aos@2.3.4/dist/aos.css" rel="stylesheet">
</head>

<body class="bg-light text-dark">
  {% include 'main_app/navbar.html' %}

  <main class="container wide-container py-5 mb-5">
    <!-- Hero Section -->
    <section class="mb-5">
      <div class="text-center text-white p-5 rounded-4 mx-3" style="background: linear-gradient(to right, #31b3fe, #7d7676);" data-aos="fade-down">
        <h1 class="fw-bold display-5 mb-4">Machine Learning Model</h1>
        <h2 class="lead text-light mb-0">Explore the algorithms, data processing, and training techniques behind our real-time motion recognition system.</h2>
      </div>
    </section>

    <!-- ML Flow Prototype Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">ML Flow Prototype</h2>
     <figure class="text-center">
         <img src="{% static 'main_app/img/ml-prototype.png' %}" 
         alt="ML Flow Prototype Diagram" 
         class="img-fluid shadow rounded mx-auto mb-2" 
         style="max-width: 1000px;">
        <figcaption class="text-muted fw-semibold small">
         Source: <a href="https://doi.org/10.1007/s11227-023-05299-9" target="_blank">Flow Prototype</a>
      </figcaption>
  </figure>
      <p class="text-muted fs-5" style="text-align: justify;">
        This flow diagram illustrates the complete machine learning pipeline used in our seizure detection system. From raw data acquisition to classification, each stage is designed to ensure reliable real-time performance in distinguishing between seizure and non-seizure motion patterns.
      </p>
      <ul class="text-muted fs-5">
       <li ><strong>Data Collection:</strong> IMU sensors capture real-time acceleration and rotation data from the user.</li>
      <li><strong>Preprocessing:</strong> Raw data is cleaned, normalized, and segmented into time windows for analysis.</li>
    <li><strong>Feature Extraction:</strong> Statistical and frequency-based features are extracted to represent motion patterns.</li>
    <li><strong>ML Methods:</strong> Machine learning models (e.g., Random Forest, SVM) are trained on labeled datasets.</li>
    <li><strong>Classification:</strong> The system classifies each time window as either “Seizure” or “Non-Seizure.”</li>
    <li><strong>Performance Evaluation:</strong> Accuracy, precision, recall, and confusion matrix are used to assess system effectiveness.</li>
  </ul>
</section>

    <!-- Data Collection Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Data Collection</h2>
      <img src="{% static 'main_app/img/hand_device.jpg' %}" alt="Hand Device" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-height: 504px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        The user wears a device which has a gyroscope, accelerometer, and a pair of sound devices which sense left and right distance from surfaces.
        This data is then written to a CSV file on the user's computer as x, y, and z rotation, x, y, and z acceleration, and left and right distances.
      </p>
    </section>

    <!-- Data Pipeline Explanation Section -->
<section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
  <h2 class="fw-bold text-primary mb-4 text-center">Data Processing and Classification Pipeline</h2>
  
  <img src="{% static 'main_app/img/preprocessing.png' %}" alt="Preprocessing and Feature Extraction" class="img-fluid shadow rounded mx-auto d-block mb-4" style="max-width: 1000px;">

  <div class="text-muted fs-5" style="text-align: justify;">
    <p><strong>Raw Sensor Data:</strong> The system captures data from wearable sensors, including:
      <ul>
        <li><strong>Accelerometer (X, Y, Z)</strong> for detecting movement intensity and direction</li>
        <li><strong>Gyroscope (Roll, Pitch, Yaw)</strong> for tracking orientation and rotation</li>
        <li><strong>Ultrasound (Distance)</strong> for measuring proximity, aiding in fall detection</li>
      </ul>
    </p>

    <p><strong>Preprocessing:</strong> Before analysis, data undergoes:
      <ul>
        <li><strong>Filtering:</strong> Noise removal for cleaner signals</li>
        <li><strong>Segmentation:</strong> Dividing data into 5-second windows for temporal analysis</li>
        <li><strong>Normalization:</strong> Ensuring consistent data ranges across features</li>
      </ul>
    </p>

    <p><strong>Feature Extraction:</strong> Features are derived from sensor data using three domains:
      <ul>
        <li><strong>Time-Domain:</strong> Jerk (dAccel/dt), Zero-Crossing Rate, Signal Magnitude Area</li>
        <li><strong>Frequency-Domain:</strong> Power Spectral Density (PSD) peaks at 3–5Hz and Spectral Entropy</li>
        <li><strong>Time-Frequency:</strong> Wavelet Coefficients capturing motion over time and frequency</li>
      </ul>
    </p>

    <p><strong>Model Inference:</strong> An LSTM Neural Network (with 3 hidden layers and dropout regularization) processes the features. A threshold ensures only predictions with >90% confidence are considered.</p>

    <p><strong>Final Output:</strong> The model classifies the user’s movement into one of the following:
      <ul>
        <li><strong>Normal Movement</strong></li>
        <li><strong>Tonic-Clonic Seizure</strong> (identified via 3–5Hz signal frequency)</li>
        <li><strong>Myoclonic Seizure</strong> (shock-like movement pattern)</li>
        <li><strong>Postural Change / Fall</strong> (detected via wavelet-based pattern)</li>
      </ul>
    </p>
  </div>
</section>


    <!-- ML Methods Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Methods</h2>
    </section>

    <!-- Classification Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Classification</h2>
      <img src="{% static 'main_app/img/classifications.png' %}" alt="Classifications" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-width: 1000px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        Four classifications are used:
      </p>
      <ul class="text-muted">
        <li><strong>Normal:</strong> Normal movement.</li>
        <li><strong>Tremor:</strong> Movement indicative of a shaky seizure.</li>
        <li><strong>Tonic:</strong> Movement indicative of a stiff seizure.</li>
        <li><strong>Posture Change:</strong> Movement indicative of a sudden posture change or a fall.</li>
      </ul>
    </section>

    <!-- Performance Evaluation Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Performance Evaluation</h2>
      <img src="{% static 'main_app/img/prediction_accuracy.png' %}" alt="Prediction Accuracy" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-width: 1000px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        Labeled data is used to analyze the accuracy of the model.
        Labels are compared against predictions, and the percentage of matching predictions are recorded and shown on the summary page.
      </p>
    </section>
    
    <!--
    TODO: decide if we want to include this section (commented out on purpose as of now; 5-12-2025)
    ML Pipeline Diagram Section 

    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">ML Pipeline Diagram</h2>
      <img src="{% static 'main_app/img/ml_pipeline.png' %}" alt="Machine Learning Pipeline Diagram" class="img-fluid mx-auto d-block mb-3" style="max-width: 900px;">

    </section>
        
    -->
    
  </main>

  {% include 'main_app/footer.html' %}

  <!-- Scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://unpkg.com/aos@2.3.4/dist/aos.js"></script>
  <script>
    AOS.init({ duration: 1000, once: true });
  </script>
  <script src="{% static 'main_app/js/darkmode.js' %}"></script>
</body>
</html>
