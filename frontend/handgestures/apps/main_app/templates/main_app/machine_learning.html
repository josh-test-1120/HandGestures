{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Machine Learning | Hand Motion Recognition Project</title>
  <link rel="stylesheet" href="{% static 'main_app/css/style.css' %}">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css" rel="stylesheet">
  <link href="https://unpkg.com/aos@2.3.4/dist/aos.css" rel="stylesheet">
</head>

<body class="bg-light text-dark">
  {% include 'main_app/navbar.html' %}

  <main class="container wide-container py-5 mb-5">
    <!-- Hero Section -->
    <section class="mb-5">
      <div class="text-center text-white p-5 rounded-4 mx-3" style="background: linear-gradient(to right, #31b3fe, #7d7676);" data-aos="fade-down">
        <h1 class="fw-bold display-5 mb-4">Machine Learning Model</h1>
        <p class="lead text-light px-md-5" style="text-align:center">
          Explore the algorithms, data processing, and training techniques behind our real-time motion recognition system.
        </p>
      </div>
    </section>

    <!-- ML Flow Prototype Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">ML Flow Prototype</h2>
      <img src="{% static 'main_app/img/ml-prototype.png' %}" alt="ML Flow Prototype Diagram" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-width: 1000px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        This flow diagram illustrates the complete machine learning pipeline used in our seizure detection system. From raw data acquisition to classification, each stage is designed to ensure reliable real-time performance in distinguishing between seizure and non-seizure motion patterns.
      </p>
      <ul class="text-muted">
        <li><strong>Data Collection:</strong> IMU sensors capture real-time acceleration and rotation data from the user.</li>
        <li><strong>Preprocessing:</strong> Raw data is cleaned, normalized, and segmented into time windows for analysis.</li>
        <li><strong>Feature Extraction:</strong> Statistical and frequency-based features are extracted to represent motion patterns.</li>
        <li><strong>ML Methods:</strong> Machine learning models (e.g., Random Forest, SVM) are trained on labeled datasets.</li>
        <li><strong>Classification:</strong> The system classifies each time window as either “Seizure” or “Non-Seizure.”</li>
        <li><strong>Performance Evaluation:</strong> Accuracy, precision, recall, and confusion matrix are used to assess system effectiveness.</li>
      </ul>
    </section>

    <!-- Data Collection Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Data Collection</h2>
      <img src="{% static 'main_app/img/hand_device.jpg' %}" alt="Hand Device" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-height: 504px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        The user wears a device which has a gyroscope, accelerometer, and a pair of sound devices which sense left and right distance from surfaces.
        This data is then written to a CSV file on the user's computer as x, y, and z rotation, x, y, and z acceleration, and left and right distances.
      </p>
    </section>

    <!-- Data Preprocessing/Feature Extraction Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Data Preprocessing and Feature Extraction</h2>
      <img src="{% static 'main_app/img/preprocessing.png' %}" alt="Preprocessing and Feature Extraction" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-width: 1000px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        Noise removal and normalization is used on the data via python functions. Data is sent in set intervals.
        Features are extracted by analyzing movement patterns within the time interval.
      </p>
    </section>

    <!-- ML Methods Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Methods</h2>
    </section>

    <!-- Classification Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Classification</h2>
      <img src="{% static 'main_app/img/classifications.png' %}" alt="Classifications" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-width: 1000px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        Four classifications are used:
      </p>
      <ul class="text-muted">
        <li><strong>Normal:</strong> Normal movement.</li>
        <li><strong>Tremor:</strong> Movement indicative of a shaky seizure.</li>
        <li><strong>Tonic:</strong> Movement indicative of a stiff seizure.</li>
        <li><strong>Posture Change:</strong> Movement indicative of a sudden posture change or a fall.</li>
      </ul>
    </section>

    <!-- Performance Evaluation Section -->
    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">Performance Evaluation</h2>
      <img src="{% static 'main_app/img/prediction_accuracy.png' %}" alt="Prediction Accuracy" class="img-fluid shadow rounded mx-auto d-block mb-3" style="max-width: 1000px;">
      <p class="text-muted fs-5" style="text-align: justify;">
        Labeled data is used to analyze the accuracy of the model.
        Labels are compared against predictions, and the percentage of matching predictions are recorded and shown on the summary page.
      </p>
    </section>
    
    <!--
    TODO: decide if we want to include this section (commented out on purpose as of now; 5-12-2025)
    ML Pipeline Diagram Section 

    <section class="card shadow-lg p-4 mb-5 rounded" data-aos="fade-up">
      <h2 class="fw-bold text-primary mb-4">ML Pipeline Diagram</h2>
      <img src="{% static 'main_app/img/ml_pipeline.png' %}" alt="Machine Learning Pipeline Diagram" class="img-fluid mx-auto d-block mb-3" style="max-width: 900px;">

    </section>
        
    -->
    
  </main>

  {% include 'main_app/footer.html' %}

  <!-- Scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://unpkg.com/aos@2.3.4/dist/aos.js"></script>
  <script>
    AOS.init({ duration: 1000, once: true });
  </script>
  <script src="{% static 'main_app/js/darkmode.js' %}"></script>
</body>
</html>
