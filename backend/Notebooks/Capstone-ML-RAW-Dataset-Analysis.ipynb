{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c387185-77ee-4f7d-b0cb-3516166a1190",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4f2a81-45c3-442d-8443-bb24de96c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Libraires\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import gc # Garbage collection for MPS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "# Pytorch libraries (Machine Learning)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "# CWT libraries\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "# PSD libraries\n",
    "from scipy.signal import welch\n",
    "from scipy.interpolate import interp1d\n",
    "import mne  # For multitaper PSD\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# TensorFlow Libraries\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History\n",
    "\n",
    "import warnings\n",
    "\n",
    "DATAFILES_DIR = '../Datafiles'\n",
    "MODELFILES_DIR = '../Models'\n",
    "UCIHARFILES_DIR = '../UCI_HAR'\n",
    "COLLECTIONFILES_DIR = '../data-collections'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93171e4-404d-4de6-9a11-882a7f359189",
   "metadata": {},
   "source": [
    "# Raw Data Preprocessor\n",
    "This includes normalization per sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8778e1-844c-4186-8c86-c0ecbf024913",
   "metadata": {},
   "source": [
    "# TNN Simple Model (Single PSD Band)\n",
    "This uses per-sample normalization and a single PSD band.\n",
    "The model itself uses TNN, PSD, and fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43b40c9-3b05-41c6-924d-235dd42cce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import welch\n",
    "\n",
    "class IMUSonarFromJSON(Dataset):\n",
    "    \"\"\"Dataset for IMU + Ultrasonic with raw + PSD output\"\"\"\n",
    "\n",
    "    cols = [\n",
    "        'AccelX(g)', 'AccelY(g)', 'AccelZ(g)',\n",
    "        'GyroX(deg/s)', 'GyroY(deg/s)', 'GyroZ(deg/s)',\n",
    "        'DistanceLeft(cm)', 'DistanceRight(cm)'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, json_file, label_map=None, transform=None, target_length=600, debug=False, add_noise=False, noise_level=0.01):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.samples = json.load(f)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.label_map = {v: k for k, v in label_map.items()} if label_map else {}\n",
    "        self.target_length = target_length\n",
    "        self.debug = debug\n",
    "\n",
    "        # New noise params:\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_level = noise_level  # e.g., 0.01 std dev\n",
    "\n",
    "        self.cols = IMUSonarFromJSON.cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def compute_global_stats(self):\n",
    "        \"\"\"Run this once before training to get mean/std across entire dataset\"\"\"\n",
    "        all_data = torch.stack([torch.tensor(self._resample_to_uniform(pd.read_csv(item['path'])))\n",
    "                                for item in self.samples])\n",
    "        self.global_mean = all_data.mean(dim=(0, 2))  # [8]\n",
    "        self.global_std = all_data.std(dim=(0, 2))    # [8]\n",
    "\n",
    "    def _resample_to_uniform(self, df):\n",
    "        \"\"\"Resample CSV data to uniform length (C, T)\"\"\"\n",
    "        timestamps = df['Timestamp(ms)'].values.astype(np.float32)\n",
    "        missing = set(self.cols) - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "        signals = df[self.cols].values.astype(np.float32)\n",
    "\n",
    "        # Remove duplicates\n",
    "        timestamps, unique_indices = np.unique(timestamps, return_index=True)\n",
    "        signals = signals[unique_indices]\n",
    "\n",
    "        # Interpolate to uniform time grid\n",
    "        uniform_timestamps = np.linspace(timestamps[0], timestamps[-1], num=self.target_length)\n",
    "        resampled = np.zeros((self.target_length, len(self.cols)), dtype=np.float32)\n",
    "        for i in range(len(self.cols)):\n",
    "            interp_func = interp1d(timestamps, signals[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled[:, i] = interp_func(uniform_timestamps)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"\\nPREPROCESSING STEPS:\")\n",
    "            print(f\"Pre-normalization mean: {resampled.mean():.4f}, std: {resampled.std():.4f}\")\n",
    "\n",
    "        # Normalize per-sample (column-wise)\n",
    "        resampled = (resampled - resampled.mean(axis=0)) / (resampled.std(axis=0) + 1e-6)\n",
    "\n",
    "        if self.add_noise:\n",
    "            noise = np.random.normal(0, self.noise_level, size=resampled.shape).astype(np.float32)\n",
    "            resampled += noise\n",
    "\n",
    "        return resampled.T  # (C, T)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_psd(data, fs=50, nperseg=128, noverlap=64):\n",
    "        \"\"\"Compute PSD for (C, T) data\"\"\"\n",
    "        C, T = data.shape\n",
    "        psd_list = []\n",
    "        for ch in range(C):\n",
    "            f, Pxx = welch(data[ch], fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "            psd_list.append(Pxx)\n",
    "        return np.stack(psd_list, axis=0).astype(np.float32)  # (C, F)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return (raw_tensor, psd_tensor, label)\"\"\"\n",
    "        item = self.samples[idx]\n",
    "        df = pd.read_csv(item['path'])\n",
    "\n",
    "        # Resample to uniform shape (C, T)\n",
    "        data = self._resample_to_uniform(df)\n",
    "\n",
    "        # # Optionally add noise to raw data during training\n",
    "        # if self.add_noise:\n",
    "        #     noise = np.random.normal(0, self.noise_level, size=data.shape).astype(np.float32)\n",
    "        #     data = data + noise\n",
    "\n",
    "        # Estimate sample frequency for PSD\n",
    "        total_time_sec = (df['Timestamp(ms)'].iloc[-1] - df['Timestamp(ms)'].iloc[0]) / 1000.0\n",
    "        fs_est = self.target_length / total_time_sec if total_time_sec > 0 else 50.0\n",
    "\n",
    "        # Compute PSD (C, F)\n",
    "        psd = self.compute_psd(data, fs=fs_est)\n",
    "\n",
    "        # Convert to tensors\n",
    "        raw_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        psd_tensor = torch.tensor(psd, dtype=torch.float32)\n",
    "\n",
    "        label = self.label_map[item['label']] if self.label_map else item['label']\n",
    "        label_tensor = torch.tensor(item['label'], dtype=torch.long)\n",
    "        if item['label'] > 27:\n",
    "            print(f'Label for {item['path']}: {item['label']}')\n",
    "        #label_tensor = torch.tensor(item['label'], dtype=torch.long)\n",
    "        #label_tensor = torch.tensor(self.label_map.get(item['label'], item['label']), dtype=torch.long)\n",
    "        # print(f'Raw Shape: {raw_tensor.shape}')\n",
    "        # print(f'PSD Shape: {psd_tensor.shape}')\n",
    "        # print(f'Label Shape: {label_tensor.shape}')\n",
    "        # print(f'Label Tensor: {label_tensor}')\n",
    "\n",
    "        return raw_tensor, psd_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383c891a-44f3-4d39-a54f-f7bc5c94aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleIMUSonarNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified model for original samples only\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels=8, num_classes=5, psd_bins=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # # --- Time domain branch ---\n",
    "        # self.time_conv = nn.Sequential(\n",
    "        #     nn.Conv1d(num_channels, 32, kernel_size=5, padding=2),\n",
    "        #     nn.BatchNorm1d(32),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.AdaptiveAvgPool1d(1)\n",
    "        # )\n",
    "        \n",
    "        # # --- PSD branch ---\n",
    "        # self.psd_fc = nn.Sequential(\n",
    "        #     nn.Linear(num_channels * psd_bins, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(dropout)\n",
    "        # )\n",
    "        \n",
    "        # # --- Fusion and classification ---\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(64 + 128, 128),  # time features + PSD features\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.Dropout(dropout),\n",
    "        #     nn.Linear(128, num_classes)\n",
    "        # )\n",
    "\n",
    "        # --- Time domain branch ---\n",
    "        self.time_conv = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/3),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/3),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        \n",
    "        # --- PSD branch ---\n",
    "        self.psd_fc = nn.Sequential(\n",
    "            nn.Linear(num_channels * psd_bins, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/2)\n",
    "        )\n",
    "        \n",
    "        # --- Fusion and classification ---\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 + 128, 256),  # More capacity\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, raw_x, psd_x):\n",
    "        # Time domain processing\n",
    "        time_features = self.time_conv(raw_x).squeeze(-1)\n",
    "        \n",
    "        # PSD processing\n",
    "        psd_flat = psd_x.view(psd_x.size(0), -1)\n",
    "        psd_features = self.psd_fc(psd_flat)\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        combined = torch.cat([time_features, psd_features], dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5d0c76-e488-49f6-bf53-4934cf7f86bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/50 - 2.1s | Train Loss: 2.5521 Acc: 0.2034 | Val Loss: 2.0818 Acc: 0.2810\n",
      "Epoch 2/50 - 1.2s | Train Loss: 1.6769 Acc: 0.4559 | Val Loss: 1.6349 Acc: 0.4876\n",
      "Epoch 3/50 - 1.2s | Train Loss: 1.3481 Acc: 0.6054 | Val Loss: 1.4506 Acc: 0.5289\n",
      "Epoch 4/50 - 1.1s | Train Loss: 1.1531 Acc: 0.6740 | Val Loss: 1.3086 Acc: 0.5537\n",
      "Epoch 5/50 - 1.2s | Train Loss: 1.0024 Acc: 0.7132 | Val Loss: 1.2460 Acc: 0.6033\n",
      "Epoch 6/50 - 1.2s | Train Loss: 0.8936 Acc: 0.7794 | Val Loss: 1.1600 Acc: 0.6694\n",
      "Epoch 7/50 - 1.1s | Train Loss: 0.8074 Acc: 0.7941 | Val Loss: 1.2016 Acc: 0.6529\n",
      "Epoch 8/50 - 1.1s | Train Loss: 0.7165 Acc: 0.8382 | Val Loss: 1.1603 Acc: 0.6446\n",
      "Epoch 9/50 - 1.1s | Train Loss: 0.6726 Acc: 0.8480 | Val Loss: 1.1886 Acc: 0.6364\n",
      "Epoch 10/50 - 1.1s | Train Loss: 0.6251 Acc: 0.8824 | Val Loss: 1.2561 Acc: 0.6198\n",
      "Epoch 11/50 - 1.2s | Train Loss: 0.5330 Acc: 0.9289 | Val Loss: 1.2193 Acc: 0.6364\n",
      "Epoch 12/50 - 1.2s | Train Loss: 0.4950 Acc: 0.9363 | Val Loss: 1.2012 Acc: 0.6860\n",
      "Epoch 13/50 - 1.1s | Train Loss: 0.4619 Acc: 0.9461 | Val Loss: 1.2586 Acc: 0.6694\n",
      "Epoch 14/50 - 1.1s | Train Loss: 0.4460 Acc: 0.9608 | Val Loss: 1.1415 Acc: 0.7107\n",
      "Epoch 15/50 - 1.1s | Train Loss: 0.4619 Acc: 0.9608 | Val Loss: 1.1872 Acc: 0.6942\n",
      "Epoch 16/50 - 1.2s | Train Loss: 0.4397 Acc: 0.9706 | Val Loss: 1.2056 Acc: 0.6860\n",
      "Epoch 17/50 - 1.1s | Train Loss: 0.4471 Acc: 0.9632 | Val Loss: 1.1833 Acc: 0.7107\n",
      "Epoch 18/50 - 1.1s | Train Loss: 0.4180 Acc: 0.9755 | Val Loss: 1.0751 Acc: 0.7025\n",
      "Epoch 19/50 - 1.1s | Train Loss: 0.4097 Acc: 0.9657 | Val Loss: 1.1908 Acc: 0.6446\n",
      "Epoch 20/50 - 1.1s | Train Loss: 0.3901 Acc: 0.9804 | Val Loss: 1.2053 Acc: 0.7190\n",
      "Epoch 21/50 - 1.1s | Train Loss: 0.4259 Acc: 0.9657 | Val Loss: 1.2367 Acc: 0.7107\n",
      "Epoch 22/50 - 1.1s | Train Loss: 0.4122 Acc: 0.9583 | Val Loss: 1.2928 Acc: 0.6777\n",
      "Epoch 23/50 - 1.1s | Train Loss: 0.4009 Acc: 0.9804 | Val Loss: 1.1965 Acc: 0.6777\n",
      "Epoch 24/50 - 1.1s | Train Loss: 0.3830 Acc: 0.9755 | Val Loss: 1.1881 Acc: 0.6860\n",
      "Epoch 25/50 - 1.1s | Train Loss: 0.3766 Acc: 0.9902 | Val Loss: 1.1803 Acc: 0.6860\n",
      "Epoch 26/50 - 1.1s | Train Loss: 0.3631 Acc: 0.9926 | Val Loss: 1.1571 Acc: 0.7190\n",
      "Epoch 27/50 - 1.1s | Train Loss: 0.3691 Acc: 0.9877 | Val Loss: 1.1835 Acc: 0.7107\n",
      "Epoch 28/50 - 1.1s | Train Loss: 0.3677 Acc: 0.9853 | Val Loss: 1.1584 Acc: 0.7355\n",
      "Epoch 29/50 - 1.1s | Train Loss: 0.3671 Acc: 0.9853 | Val Loss: 1.1410 Acc: 0.7190\n",
      "Epoch 30/50 - 1.2s | Train Loss: 0.3700 Acc: 0.9926 | Val Loss: 1.1535 Acc: 0.7190\n",
      "Epoch 31/50 - 1.2s | Train Loss: 0.3536 Acc: 0.9951 | Val Loss: 1.1504 Acc: 0.7438\n",
      "Epoch 32/50 - 1.1s | Train Loss: 0.3406 Acc: 1.0000 | Val Loss: 1.1525 Acc: 0.7355\n",
      "Epoch 33/50 - 1.1s | Train Loss: 0.3632 Acc: 0.9926 | Val Loss: 1.1684 Acc: 0.6942\n",
      "Epoch 34/50 - 1.1s | Train Loss: 0.3465 Acc: 0.9951 | Val Loss: 1.1394 Acc: 0.7273\n",
      "Epoch 35/50 - 1.1s | Train Loss: 0.3789 Acc: 0.9828 | Val Loss: 1.1392 Acc: 0.7355\n",
      "Epoch 36/50 - 1.1s | Train Loss: 0.3617 Acc: 0.9902 | Val Loss: 1.1430 Acc: 0.7190\n",
      "Epoch 37/50 - 1.1s | Train Loss: 0.3505 Acc: 0.9951 | Val Loss: 1.1449 Acc: 0.7273\n",
      "Epoch 38/50 - 1.1s | Train Loss: 0.3546 Acc: 1.0000 | Val Loss: 1.1449 Acc: 0.7273\n",
      "Epoch 39/50 - 1.2s | Train Loss: 0.3515 Acc: 1.0000 | Val Loss: 1.1407 Acc: 0.7355\n",
      "Epoch 40/50 - 1.2s | Train Loss: 0.3675 Acc: 0.9926 | Val Loss: 1.1447 Acc: 0.7273\n",
      "Epoch 41/50 - 1.1s | Train Loss: 0.3705 Acc: 0.9853 | Val Loss: 1.1392 Acc: 0.7190\n",
      "Epoch 42/50 - 1.1s | Train Loss: 0.3521 Acc: 0.9902 | Val Loss: 1.1386 Acc: 0.7438\n",
      "Epoch 43/50 - 1.1s | Train Loss: 0.3644 Acc: 0.9926 | Val Loss: 1.1370 Acc: 0.7190\n",
      "Epoch 44/50 - 1.2s | Train Loss: 0.3446 Acc: 0.9975 | Val Loss: 1.1199 Acc: 0.7355\n",
      "Epoch 45/50 - 1.1s | Train Loss: 0.3471 Acc: 0.9951 | Val Loss: 1.1277 Acc: 0.7438\n",
      "Epoch 46/50 - 1.1s | Train Loss: 0.3641 Acc: 0.9877 | Val Loss: 1.1294 Acc: 0.7355\n",
      "Epoch 47/50 - 1.1s | Train Loss: 0.3480 Acc: 0.9951 | Val Loss: 1.1299 Acc: 0.7355\n",
      "Epoch 48/50 - 1.1s | Train Loss: 0.3620 Acc: 0.9902 | Val Loss: 1.1373 Acc: 0.7190\n",
      "Epoch 49/50 - 1.1s | Train Loss: 0.3644 Acc: 0.9853 | Val Loss: 1.1339 Acc: 0.7355\n",
      "Epoch 50/50 - 1.1s | Train Loss: 0.3537 Acc: 0.9975 | Val Loss: 1.1385 Acc: 0.7438\n",
      "Final Results:\n",
      "Train loss: 0.3145, accuracy: 1.0000\n",
      "Test loss: 1.1082, accuracy: 0.7438\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------- Data ----------------\n",
    "with open(f\"{DATAFILES_DIR}/compressed_label_map.json\", 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "train_dataset = IMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/train_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    noise_level=0.001,\n",
    "    # window_length=128,\n",
    "    # stride=32,          # lots of windows\n",
    "    add_noise=True      # enable training-time augmentation\n",
    ")\n",
    "test_dataset = IMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/test_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    # window_length=128,\n",
    "    # stride=32,   # lots of windows\n",
    "    add_noise=False\n",
    ")\n",
    "\n",
    "# Compute global stats on TRAIN ONLY, then share with TEST\n",
    "train_dataset.compute_global_stats()\n",
    "test_dataset.global_mean = train_dataset.global_mean.clone()\n",
    "test_dataset.global_std  = train_dataset.global_std.clone()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=0, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "sample_raw, sample_psd, _ = train_dataset[0]\n",
    "num_channels = sample_raw.shape[0]\n",
    "psd_bins = sample_psd.shape[1]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "model = SimpleIMUSonarNet(\n",
    "    num_channels=num_channels,\n",
    "    num_classes=num_classes,\n",
    "    psd_bins=psd_bins,\n",
    "    dropout=0.2               # slightly higher dropout to curb overfit\n",
    ").to(device)\n",
    "\n",
    "# ---------------- Train loop ----------------\n",
    "epochs = 50\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # stronger label smoothing\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0.0\n",
    "patience = 5\n",
    "no_improve_epochs = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    epoch_start = time()\n",
    "    \n",
    "    for raw_batch, psd_batch, labels in train_loader:\n",
    "        raw_batch = raw_batch.to(device)\n",
    "        psd_batch = psd_batch.to(device)\n",
    "        labels    = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(raw_batch, psd_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in test_loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels    = labels.to(device).long()\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total   += labels.size(0)\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc  = correct / total\n",
    "    val_loss   = val_loss / len(test_loader)\n",
    "    val_acc    = val_correct / val_total\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - {time() - epoch_start:.1f}s | \" \\\n",
    "            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \" \\\n",
    "            f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         no_improve_epochs = 0\n",
    "#         best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "#     else:\n",
    "#         no_improve_epochs += 1\n",
    "#         if no_improve_epochs >= patience:\n",
    "#             print(f\"⏹ Early stopping at epoch {epoch+1} (best val acc {best_val_acc:.4f})\")\n",
    "#             break\n",
    "\n",
    "# # Restore best model\n",
    "# if best_state is not None:\n",
    "#     model.load_state_dict(best_state)\n",
    "\n",
    "# ---------------- Final evaluation ----------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels    = labels.to(device).long()\n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            total_loss += criterion(outputs, labels).item() * raw_batch.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "train_loss, train_acc = evaluate(model, train_loader)\n",
    "test_loss,  test_acc  = evaluate(model, test_loader)\n",
    "\n",
    "print('Final Results:')\n",
    "print(f'Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}')\n",
    "print(f'Test loss: {test_loss:.4f}, accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8a5cc-b26c-43fb-9949-90ccebda1678",
   "metadata": {},
   "source": [
    "## Dataset Wide normalization\n",
    "This normalization is done dataset-wide, and each channel is adjusted differently, mainly to clamp ultrasonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74deeab8-1f41-4419-8735-751a4fc53df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import welch\n",
    "\n",
    "class WideNormalizationIMUSonarFromJSON(IMUSonarFromJSON):\n",
    "    \"\"\"Dataset for IMU + Ultrasonic with raw + PSD output\n",
    "    includes dataset -ide normalization\"\"\"\n",
    "\n",
    "    def compute_global_stats(self):\n",
    "        \"\"\"Compute mean/std over raw resampled data (no normalization, no aug).\"\"\"\n",
    "        tensors = []\n",
    "        for item in self.samples:\n",
    "            df = pd.read_csv(item['path'])\n",
    "    \n",
    "            # --- identical resampling as in _resample_to_uniform, but NO normalization/aug ---\n",
    "            timestamps = df['Timestamp(ms)'].values.astype(np.float32)\n",
    "            missing = set(self.cols) - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing required columns: {missing}\")\n",
    "    \n",
    "            signals = df[self.cols].values.astype(np.float32)\n",
    "    \n",
    "            # Remove duplicates\n",
    "            timestamps, unique_indices = np.unique(timestamps, return_index=True)\n",
    "            signals = signals[unique_indices]\n",
    "    \n",
    "            # Interpolate to uniform time grid\n",
    "            uniform_timestamps = np.linspace(timestamps[0], timestamps[-1], num=self.target_length)\n",
    "            resampled = np.zeros((self.target_length, len(self.cols)), dtype=np.float32)\n",
    "            for i in range(len(self.cols)):\n",
    "                interp_func = interp1d(timestamps, signals[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "                resampled[:, i] = interp_func(uniform_timestamps)\n",
    "    \n",
    "            # (C, T) — crucially, do NOT normalize or augment here\n",
    "            tensors.append(torch.tensor(resampled.T, dtype=torch.float32))\n",
    "    \n",
    "        all_data = torch.stack(tensors, dim=0)  # (N, C, T)\n",
    "        self.global_mean = all_data.mean(dim=(0, 2))  # [C]\n",
    "        self.global_std  = all_data.std(dim=(0, 2))   # [C]\n",
    "\n",
    "    def _augment_raw(self, raw, noise_level=0.001, scale_range=(0.98,1.02),\n",
    "                     mask_prob=0.05, jitter_std=0.005):\n",
    "        \"\"\"Augment a single sample in (C, T)\"\"\"\n",
    "        if isinstance(raw, np.ndarray):\n",
    "            raw = torch.tensor(raw, dtype=torch.float32)\n",
    "    \n",
    "        C, T = raw.shape\n",
    "        augmented = raw.clone()\n",
    "    \n",
    "        imu_channels = list(range(6))\n",
    "        sonar_channels = [6,7]\n",
    "    \n",
    "        # Gaussian noise\n",
    "        noise = torch.randn(len(imu_channels), T) * noise_level\n",
    "        augmented[imu_channels,:] += noise\n",
    "    \n",
    "        # Small temporal scaling\n",
    "        scale = torch.empty(1).uniform_(*scale_range)\n",
    "        augmented[imu_channels,:] *= scale\n",
    "    \n",
    "        # Small amplitude jitter\n",
    "        jitter = 1.0 + torch.randn(len(imu_channels), T) * jitter_std\n",
    "        augmented[imu_channels,:] *= jitter\n",
    "    \n",
    "        # Random masking\n",
    "        mask = (torch.rand(len(imu_channels), T) < mask_prob)\n",
    "        augmented[imu_channels,:][mask] = 0.0\n",
    "    \n",
    "        # Clamp sonar\n",
    "        augmented[sonar_channels,:] = torch.clamp(augmented[sonar_channels,:], 0.0, 1.0)\n",
    "    \n",
    "        return augmented\n",
    "\n",
    "    def _augment_raw_normalized(self, raw, noise_level=0.01, scale_range=(0.98, 1.02),\n",
    "                 mask_prob=0.01, jitter_std=0.01):\n",
    "        \"\"\"Augment a single sample in (C, T) for normalized data\"\"\"\n",
    "        if isinstance(raw, np.ndarray):\n",
    "            raw = torch.tensor(raw, dtype=torch.float32)\n",
    "    \n",
    "        C, T = raw.shape\n",
    "        augmented = raw.clone()\n",
    "\n",
    "        self.accel_channels = [0,1,2]\n",
    "        self.gyro_channels = [3,4,5]\n",
    "        self.sonar_channels = [6,7]\n",
    "    \n",
    "        # Gaussian noise - increased for normalized scale\n",
    "        noise = torch.randn(len(self.accel_channels) + len(self.gyro_channels), T) * noise_level\n",
    "        augmented[self.accel_channels + self.gyro_channels,:] += noise\n",
    "    \n",
    "        # Temporal scaling - wider range for normalized data\n",
    "        scale = torch.empty(1).uniform_(*scale_range)\n",
    "        augmented[self.accel_channels + self.gyro_channels,:] *= scale\n",
    "    \n",
    "        # Amplitude jitter - increased for normalized scale\n",
    "        jitter = 1.0 + torch.randn(len(self.accel_channels) + len(self.gyro_channels), T) * jitter_std\n",
    "        augmented[self.accel_channels + self.gyro_channels,:] *= jitter\n",
    "    \n",
    "        # Random masking - slightly increased\n",
    "        mask = (torch.rand(len(self.accel_channels) + len(self.gyro_channels), T) < mask_prob)\n",
    "        augmented[self.accel_channels + self.gyro_channels,:][mask] = 0.0\n",
    "    \n",
    "        # Clamp sonar - remove or adjust for normalized data\n",
    "        # augmented[self.sonar_channels,:] = torch.clamp(augmented[self.sonar_channels,:], -3.0, 3.0)\n",
    "        # Consider removing clamping entirely for normalized data\n",
    "    \n",
    "        return augmented\n",
    "\n",
    "    def _resample_to_uniform(self, df):\n",
    "        \"\"\"Resample CSV data to uniform length (C, T)\"\"\"\n",
    "        timestamps = df['Timestamp(ms)'].values.astype(np.float32)\n",
    "        missing = set(self.cols) - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "        signals = df[self.cols].values.astype(np.float32)\n",
    "\n",
    "        # Remove duplicates\n",
    "        timestamps, unique_indices = np.unique(timestamps, return_index=True)\n",
    "        signals = signals[unique_indices]\n",
    "\n",
    "        # Interpolate to uniform time grid\n",
    "        uniform_timestamps = np.linspace(timestamps[0], timestamps[-1], num=self.target_length)\n",
    "        resampled = np.zeros((self.target_length, len(self.cols)), dtype=np.float32)\n",
    "        for i in range(len(self.cols)):\n",
    "            interp_func = interp1d(timestamps, signals[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled[:, i] = interp_func(uniform_timestamps)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"\\nPREPROCESSING STEPS:\")\n",
    "            print(f\"Pre-normalization mean: {resampled.mean():.4f}, std: {resampled.std():.4f}\")\n",
    "\n",
    "        # Global or per-sample normalization\n",
    "        if hasattr(self, \"global_mean\") and hasattr(self, \"global_std\"):\n",
    "            resampled = (resampled - self.global_mean.numpy()) / (self.global_std.numpy() + 1e-6)\n",
    "        else:\n",
    "            resampled = (resampled - resampled.mean(axis=0)) / (resampled.std(axis=0) + 1e-6)\n",
    "\n",
    "        if self.add_noise and torch.rand(1) < 0.5:\n",
    "            resampled = self._augment_raw_normalized(resampled.T).T  # augment in (C, T), return to (T, C) before transpose\n",
    "\n",
    "        return resampled.T  # (C, T)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return (raw_tensor, psd_tensor, label)\"\"\"\n",
    "        item = self.samples[idx]\n",
    "        df = pd.read_csv(item['path'])\n",
    "\n",
    "        # Resample to uniform shape (C, T)\n",
    "        data = self._resample_to_uniform(df)\n",
    "\n",
    "        # Estimate sample frequency for PSD\n",
    "        total_time_sec = (df['Timestamp(ms)'].iloc[-1] - df['Timestamp(ms)'].iloc[0]) / 1000.0\n",
    "        fs_est = self.target_length / total_time_sec if total_time_sec > 0 else 50.0\n",
    "\n",
    "        # Compute PSD (C, F)\n",
    "        psd = self.compute_psd(data, fs=fs_est)\n",
    "\n",
    "        # Convert to tensors\n",
    "        #raw_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        if isinstance(data, np.ndarray): raw_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        else: raw_tensor = data\n",
    "        psd_tensor = torch.tensor(psd, dtype=torch.float32)\n",
    "\n",
    "        label = self.label_map[item['label']] if self.label_map else item['label']\n",
    "        label_tensor = torch.tensor(item['label'], dtype=torch.long)\n",
    "        if item['label'] > 27:\n",
    "            print(f'Label for {item[\"path\"]}: {item[\"label\"]}')\n",
    "\n",
    "        return raw_tensor, psd_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3dcdad76-06f4-45d3-99b6-bc29d840d162",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import welch\n",
    "\n",
    "class WideNormalizationPerChannelIMUSonarFromJSON(IMUSonarFromJSON):\n",
    "    \"\"\"Dataset for IMU + Ultrasonic with raw + PSD output\n",
    "    includes dataset-wide normalization with sensor grouping\"\"\"\n",
    "\n",
    "    def __init__(self, json_file, label_map=None, transform=None,\n",
    "                 target_length=600, window_length=128, stride=64,\n",
    "                 debug=False, add_noise=False, noise_level=0.01):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.samples = json.load(f)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.label_map = {v: k for k, v in label_map.items()} if label_map else {}\n",
    "        self.target_length = target_length\n",
    "        self.window_length = window_length\n",
    "        self.stride = stride\n",
    "        self.debug = debug\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "        # Define sensor channel groups\n",
    "        self.cols = IMUSonarFromJSON.cols\n",
    "        self.accel_channels = [0, 1, 2]    # First 3 channels\n",
    "        self.gyro_channels = [3, 4, 5]     # Next 3 channels  \n",
    "        self.sonar_channels = [6, 7]       # Last 2 channels\n",
    "\n",
    "        # Build window index\n",
    "        self.window_index = []\n",
    "        for i, item in enumerate(self.samples):\n",
    "            T = self.target_length\n",
    "            if T < self.window_length:\n",
    "                self.window_index.append((i, 0, T))\n",
    "            else:\n",
    "                for start in range(0, T - self.window_length + 1, self.stride):\n",
    "                    end = start + self.window_length\n",
    "                    self.window_index.append((i, start, end))\n",
    "\n",
    "    def compute_global_stats(self):\n",
    "        \"\"\"Compute mean/std over raw resampled data for each sensor group\"\"\"\n",
    "        tensors = []\n",
    "        for item in self.samples:\n",
    "            df = pd.read_csv(item['path'])\n",
    "            \n",
    "            # Identical resampling as in _resample_to_uniform, but NO normalization/aug\n",
    "            timestamps = df['Timestamp(ms)'].values.astype(np.float32)\n",
    "            signals = df[self.cols].values.astype(np.float32)\n",
    "\n",
    "            timestamps, unique_indices = np.unique(timestamps, return_index=True)\n",
    "            signals = signals[unique_indices]\n",
    "\n",
    "            uniform_timestamps = np.linspace(timestamps[0], timestamps[-1], num=self.target_length)\n",
    "            resampled = np.zeros((self.target_length, len(self.cols)), dtype=np.float32)\n",
    "            for i in range(len(self.cols)):\n",
    "                interp_func = interp1d(timestamps, signals[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "                resampled[:, i] = interp_func(uniform_timestamps)\n",
    "\n",
    "            tensors.append(torch.tensor(resampled.T, dtype=torch.float32))\n",
    "\n",
    "        all_data = torch.stack(tensors, dim=0)  # (N, C, T)\n",
    "        \n",
    "        # Calculate statistics for each sensor group\n",
    "        self.global_mean = all_data.mean(dim=(0, 2))  # [C] - per channel mean\n",
    "        self.global_std = all_data.std(dim=(0, 2))    # [C] - per channel std\n",
    "        \n",
    "        # # Calculate group statistics (mean of means, mean of stds for each group)\n",
    "        # self.accel_mean = self.global_mean[self.accel_channels].mean()\n",
    "        # self.accel_std = self.global_std[self.accel_channels].mean()\n",
    "        \n",
    "        # self.gyro_mean = self.global_mean[self.gyro_channels].mean() \n",
    "        # self.gyro_std = self.global_std[self.gyro_channels].mean()\n",
    "        \n",
    "        # self.sonar_mean = self.global_mean[self.sonar_channels].mean()\n",
    "        # self.sonar_std = self.global_std[self.sonar_channels].mean()\n",
    "\n",
    "    def _apply_sensor_group_normalization(self, data):\n",
    "        \"\"\"Apply sensor group normalization (Strategy 1)\"\"\"\n",
    "        # Convert to numpy if it's a tensor\n",
    "        if torch.is_tensor(data):\n",
    "            data = data.numpy()\n",
    "            \n",
    "        normalized = data.copy()\n",
    "        \n",
    "        # Convert tensor stats to numpy for compatibility\n",
    "        accel_mean = self.accel_mean.item() if torch.is_tensor(self.accel_mean) else self.accel_mean\n",
    "        accel_std = self.accel_std.item() if torch.is_tensor(self.accel_std) else self.accel_std\n",
    "        gyro_mean = self.gyro_mean.item() if torch.is_tensor(self.gyro_mean) else self.gyro_mean\n",
    "        gyro_std = self.gyro_std.item() if torch.is_tensor(self.gyro_std) else self.gyro_std\n",
    "        sonar_mean = self.sonar_mean.item() if torch.is_tensor(self.sonar_mean) else self.sonar_mean\n",
    "        sonar_std = self.sonar_std.item() if torch.is_tensor(self.sonar_std) else self.sonar_std\n",
    "        \n",
    "        # Normalize accelerometer channels as a group\n",
    "        normalized[self.accel_channels] = (normalized[self.accel_channels] - accel_mean) / (accel_std + 1e-6)\n",
    "        \n",
    "        # Normalize gyroscope channels as a group  \n",
    "        normalized[self.gyro_channels] = (normalized[self.gyro_channels] - gyro_mean) / (gyro_std + 1e-6)\n",
    "        \n",
    "        # Normalize sonar channels as a group\n",
    "        normalized[self.sonar_channels] = (normalized[self.sonar_channels] - sonar_mean) / (sonar_std + 1e-6)\n",
    "        \n",
    "        return torch.tensor(normalized, dtype=torch.float32)\n",
    "\n",
    "    def _apply_per_channel_normalization(self, data):\n",
    "        \"\"\"Apply per-channel normalization (Strategy 2) - MOST LIKELY TO WIN\"\"\"\n",
    "        # Convert to tensor first\n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "            \n",
    "        normalized = data.clone()\n",
    "        \n",
    "        # Normalize each channel independently using its own statistics\n",
    "        for i in range(data.shape[0]):\n",
    "            normalized[i] = (normalized[i] - self.global_mean[i]) / (self.global_std[i] + 1e-6)\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "    def _augment_raw(self, raw, noise_level=0.002, scale_range=(0.98,1.02),\n",
    "                     mask_prob=0.05, jitter_std=0.01):\n",
    "        \"\"\"Augment a single sample in (C, T)\"\"\"\n",
    "        if isinstance(raw, np.ndarray):\n",
    "            raw = torch.tensor(raw, dtype=torch.float32)\n",
    "\n",
    "        C, T = raw.shape\n",
    "        augmented = raw.clone()\n",
    "\n",
    "        # Gaussian noise\n",
    "        noise = torch.randn(len(self.accel_channels) + len(self.gyro_channels), T) * noise_level\n",
    "        augmented[self.accel_channels + self.gyro_channels,:] += noise\n",
    "\n",
    "        # Small temporal scaling\n",
    "        scale = torch.empty(1).uniform_(*scale_range)\n",
    "        augmented[self.accel_channels + self.gyro_channels,:] *= scale\n",
    "\n",
    "        # Small amplitude jitter\n",
    "        jitter = 1.0 + torch.randn(len(self.accel_channels) + len(self.gyro_channels), T) * jitter_std\n",
    "        augmented[self.accel_channels + self.gyro_channels,:] *= jitter\n",
    "\n",
    "        # Random masking\n",
    "        mask = (torch.rand(len(self.accel_channels) + len(self.gyro_channels), T) < mask_prob)\n",
    "        augmented[self.accel_channels + self.gyro_channels,:][mask] = 0.0\n",
    "\n",
    "        # Clamp sonar\n",
    "        augmented[self.sonar_channels,:] = torch.clamp(augmented[self.sonar_channels,:], 0.0, 1.0)\n",
    "\n",
    "        return augmented\n",
    "\n",
    "    def _resample_to_uniform(self, df):\n",
    "        \"\"\"Resample CSV data to uniform length (C, T) - NO NORMALIZATION HERE\"\"\"\n",
    "        timestamps = df['Timestamp(ms)'].values.astype(np.float32)\n",
    "        signals = df[self.cols].values.astype(np.float32)\n",
    "\n",
    "        # Remove duplicates\n",
    "        timestamps, unique_indices = np.unique(timestamps, return_index=True)\n",
    "        signals = signals[unique_indices]\n",
    "\n",
    "        # Interpolate to uniform time grid\n",
    "        uniform_timestamps = np.linspace(timestamps[0], timestamps[-1], num=self.target_length)\n",
    "        resampled = np.zeros((self.target_length, len(self.cols)), dtype=np.float32)\n",
    "        for i in range(len(self.cols)):\n",
    "            interp_func = interp1d(timestamps, signals[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled[:, i] = interp_func(uniform_timestamps)\n",
    "\n",
    "        return resampled.T  # (C, T) - RAW, unnormalized data\n",
    "\n",
    "    def compute_psd(self, data, fs=50):\n",
    "        \"\"\"Compute PSD for (C, T) data\"\"\"\n",
    "        C, T = data.shape\n",
    "        nperseg = min(self.window_length, T)\n",
    "        noverlap = nperseg // 2\n",
    "        \n",
    "        psd_list = []\n",
    "        for ch in range(C):\n",
    "            f, Pxx = welch(data[ch], fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "            psd_list.append(Pxx)\n",
    "        return np.stack(psd_list, axis=0).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx, start, end = self.window_index[idx]\n",
    "        item = self.samples[sample_idx]\n",
    "        df = pd.read_csv(item['path'])\n",
    "\n",
    "        # Resample to get raw data (C, T)\n",
    "        full_data = self._resample_to_uniform(df)\n",
    "        data = full_data[:, start:end]  # Slice the window\n",
    "\n",
    "        # Apply sensor group normalization (STRATEGY 1)\n",
    "        #data = self._apply_sensor_group_normalization(data)\n",
    "        data = self._apply_per_channel_normalization(data)\n",
    "\n",
    "        # Apply augmentation if enabled (after normalization)\n",
    "        if self.add_noise and torch.rand(1) < 0.5:\n",
    "            data = self._augment_raw(data)\n",
    "\n",
    "        # Estimate sample frequency for PSD\n",
    "        total_time_sec = (df['Timestamp(ms)'].iloc[-1] - df['Timestamp(ms)'].iloc[0]) / 1000.0\n",
    "        fs_est = self.target_length / total_time_sec if total_time_sec > 0 else 50.0\n",
    "\n",
    "        # Compute PSD\n",
    "        psd = self.compute_psd(data.numpy(), fs=fs_est)\n",
    "\n",
    "        return data, torch.tensor(psd, dtype=torch.float32), torch.tensor(item['label'], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74629d33-0728-4f30-9e84-e4704a456634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 1/50 - 1.3s | Train Loss: 2.2215 Acc: 0.3113 | Val Loss: 1.6636 Acc: 0.4380\n",
      "Epoch 2/50 - 1.3s | Train Loss: 1.5661 Acc: 0.5196 | Val Loss: 1.3167 Acc: 0.6281\n",
      "Epoch 3/50 - 1.2s | Train Loss: 1.2353 Acc: 0.6250 | Val Loss: 1.1501 Acc: 0.6694\n",
      "Epoch 4/50 - 1.2s | Train Loss: 1.0741 Acc: 0.6887 | Val Loss: 1.1480 Acc: 0.6612\n",
      "Epoch 5/50 - 1.3s | Train Loss: 1.0097 Acc: 0.6985 | Val Loss: 1.0302 Acc: 0.6777\n",
      "Epoch 6/50 - 1.2s | Train Loss: 0.8919 Acc: 0.7672 | Val Loss: 0.9878 Acc: 0.7603\n",
      "Epoch 7/50 - 1.3s | Train Loss: 0.8649 Acc: 0.7745 | Val Loss: 1.0145 Acc: 0.7190\n",
      "Epoch 8/50 - 1.2s | Train Loss: 0.7938 Acc: 0.7966 | Val Loss: 1.0453 Acc: 0.7603\n",
      "Epoch 9/50 - 1.2s | Train Loss: 0.7447 Acc: 0.8382 | Val Loss: 1.0172 Acc: 0.7438\n",
      "Epoch 10/50 - 1.2s | Train Loss: 0.7329 Acc: 0.8137 | Val Loss: 0.9465 Acc: 0.7686\n",
      "Epoch 11/50 - 1.2s | Train Loss: 0.7007 Acc: 0.8309 | Val Loss: 1.0797 Acc: 0.7273\n",
      "Epoch 12/50 - 1.2s | Train Loss: 0.6510 Acc: 0.8603 | Val Loss: 1.0327 Acc: 0.7603\n",
      "Epoch 13/50 - 1.3s | Train Loss: 0.5791 Acc: 0.8848 | Val Loss: 0.9860 Acc: 0.7521\n",
      "Epoch 14/50 - 1.3s | Train Loss: 0.6236 Acc: 0.8848 | Val Loss: 1.0145 Acc: 0.7686\n",
      "Epoch 15/50 - 1.2s | Train Loss: 0.5849 Acc: 0.8971 | Val Loss: 1.0118 Acc: 0.7438\n",
      "Epoch 16/50 - 1.2s | Train Loss: 0.5877 Acc: 0.8922 | Val Loss: 0.9548 Acc: 0.7603\n",
      "Epoch 17/50 - 1.2s | Train Loss: 0.5198 Acc: 0.9338 | Val Loss: 0.9423 Acc: 0.7686\n",
      "Epoch 18/50 - 1.2s | Train Loss: 0.5324 Acc: 0.9216 | Val Loss: 0.9575 Acc: 0.7851\n",
      "Epoch 19/50 - 1.2s | Train Loss: 0.5014 Acc: 0.9289 | Val Loss: 0.9120 Acc: 0.8017\n",
      "Epoch 20/50 - 1.2s | Train Loss: 0.4840 Acc: 0.9338 | Val Loss: 0.8845 Acc: 0.7769\n",
      "Epoch 21/50 - 1.2s | Train Loss: 0.4711 Acc: 0.9461 | Val Loss: 0.9349 Acc: 0.7851\n",
      "Epoch 22/50 - 1.2s | Train Loss: 0.4735 Acc: 0.9412 | Val Loss: 0.9646 Acc: 0.7686\n",
      "Epoch 23/50 - 1.2s | Train Loss: 0.4739 Acc: 0.9510 | Val Loss: 0.9729 Acc: 0.7686\n",
      "Epoch 24/50 - 1.2s | Train Loss: 0.4651 Acc: 0.9436 | Val Loss: 0.8701 Acc: 0.7769\n",
      "Epoch 25/50 - 1.2s | Train Loss: 0.4504 Acc: 0.9534 | Val Loss: 0.9196 Acc: 0.7686\n",
      "Epoch 26/50 - 1.2s | Train Loss: 0.4620 Acc: 0.9485 | Val Loss: 0.9187 Acc: 0.7769\n",
      "Epoch 27/50 - 1.2s | Train Loss: 0.4185 Acc: 0.9681 | Val Loss: 0.9321 Acc: 0.7521\n",
      "Epoch 28/50 - 1.2s | Train Loss: 0.4755 Acc: 0.9436 | Val Loss: 0.9086 Acc: 0.7851\n",
      "Epoch 29/50 - 1.2s | Train Loss: 0.4332 Acc: 0.9608 | Val Loss: 0.9106 Acc: 0.7686\n",
      "Epoch 30/50 - 1.2s | Train Loss: 0.4201 Acc: 0.9559 | Val Loss: 0.9613 Acc: 0.7686\n",
      "Epoch 31/50 - 1.2s | Train Loss: 0.4224 Acc: 0.9632 | Val Loss: 0.9676 Acc: 0.7603\n",
      "Epoch 32/50 - 1.2s | Train Loss: 0.4095 Acc: 0.9730 | Val Loss: 0.8968 Acc: 0.8017\n",
      "Epoch 33/50 - 1.2s | Train Loss: 0.4141 Acc: 0.9755 | Val Loss: 0.8823 Acc: 0.7934\n",
      "Epoch 34/50 - 1.2s | Train Loss: 0.3927 Acc: 0.9779 | Val Loss: 0.9023 Acc: 0.7851\n",
      "Epoch 35/50 - 1.2s | Train Loss: 0.3694 Acc: 0.9951 | Val Loss: 0.8891 Acc: 0.7934\n",
      "Epoch 36/50 - 1.2s | Train Loss: 0.4065 Acc: 0.9706 | Val Loss: 0.9068 Acc: 0.7769\n",
      "Epoch 37/50 - 1.2s | Train Loss: 0.3693 Acc: 0.9902 | Val Loss: 0.9211 Acc: 0.7603\n",
      "Epoch 38/50 - 1.2s | Train Loss: 0.4080 Acc: 0.9730 | Val Loss: 0.9113 Acc: 0.7769\n",
      "Epoch 39/50 - 1.3s | Train Loss: 0.3682 Acc: 0.9853 | Val Loss: 0.8947 Acc: 0.7769\n",
      "Epoch 40/50 - 1.3s | Train Loss: 0.3899 Acc: 0.9730 | Val Loss: 0.9114 Acc: 0.7769\n",
      "Epoch 41/50 - 1.2s | Train Loss: 0.3724 Acc: 0.9828 | Val Loss: 0.9042 Acc: 0.7769\n",
      "Epoch 42/50 - 1.2s | Train Loss: 0.3758 Acc: 0.9877 | Val Loss: 0.8992 Acc: 0.7851\n",
      "Epoch 43/50 - 1.3s | Train Loss: 0.3686 Acc: 0.9877 | Val Loss: 0.9125 Acc: 0.7851\n",
      "Epoch 44/50 - 1.3s | Train Loss: 0.3840 Acc: 0.9779 | Val Loss: 0.9212 Acc: 0.7769\n",
      "Epoch 45/50 - 1.2s | Train Loss: 0.3882 Acc: 0.9853 | Val Loss: 0.9016 Acc: 0.7851\n",
      "Epoch 46/50 - 1.2s | Train Loss: 0.3784 Acc: 0.9877 | Val Loss: 0.9045 Acc: 0.7769\n",
      "Epoch 47/50 - 1.3s | Train Loss: 0.3709 Acc: 0.9877 | Val Loss: 0.9020 Acc: 0.7769\n",
      "Epoch 48/50 - 1.2s | Train Loss: 0.3826 Acc: 0.9779 | Val Loss: 0.9126 Acc: 0.7769\n",
      "Epoch 49/50 - 1.2s | Train Loss: 0.3733 Acc: 0.9902 | Val Loss: 0.9141 Acc: 0.7769\n",
      "Epoch 50/50 - 1.2s | Train Loss: 0.3829 Acc: 0.9877 | Val Loss: 0.9109 Acc: 0.7769\n",
      "Final Results:\n",
      "Train loss: 0.3145, accuracy: 1.0000\n",
      "Test loss: 0.8813, accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------- Data ----------------\n",
    "with open(f\"{DATAFILES_DIR}/compressed_label_map.json\", 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "train_dataset = WideNormalizationIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/train_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    noise_level=0.001,\n",
    "    # window_length=128,\n",
    "    # stride=32,          # lots of windows\n",
    "    add_noise=True      # enable training-time augmentation\n",
    ")\n",
    "test_dataset = WideNormalizationIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/test_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    # window_length=128,\n",
    "    # stride=32,   # lots of windows\n",
    "    add_noise=False\n",
    ")\n",
    "\n",
    "# Compute global stats on TRAIN ONLY, then share with TEST\n",
    "train_dataset.compute_global_stats()\n",
    "test_dataset.global_mean = train_dataset.global_mean.clone()\n",
    "test_dataset.global_std  = train_dataset.global_std.clone()\n",
    "# Per sensor stats\n",
    "# test_dataset.accel_mean = train_dataset.accel_mean\n",
    "# test_dataset.accel_std = train_dataset.accel_std\n",
    "# test_dataset.gyro_mean = train_dataset.gyro_mean\n",
    "# test_dataset.gyro_std = train_dataset.gyro_std  \n",
    "# test_dataset.sonar_mean = train_dataset.sonar_mean\n",
    "# test_dataset.sonar_std = train_dataset.sonar_std\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=0, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "sample_raw, sample_psd, _ = train_dataset[0]\n",
    "num_channels = sample_raw.shape[0]\n",
    "psd_bins = sample_psd.shape[1]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "model = SimpleIMUSonarNet(\n",
    "    num_channels=num_channels,\n",
    "    num_classes=num_classes,\n",
    "    psd_bins=psd_bins,\n",
    "    dropout=0.2               # slightly higher dropout to curb overfit\n",
    ").to(device)\n",
    "\n",
    "# ---------------- Train loop ----------------\n",
    "epochs = 50\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # stronger label smoothing\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0.0\n",
    "patience = 5\n",
    "no_improve_epochs = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    epoch_start = time()\n",
    "    \n",
    "    for raw_batch, psd_batch, labels in train_loader:\n",
    "        raw_batch = raw_batch.to(device)\n",
    "        psd_batch = psd_batch.to(device)\n",
    "        labels    = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(raw_batch, psd_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in test_loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels    = labels.to(device).long()\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total   += labels.size(0)\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc  = correct / total\n",
    "    val_loss   = val_loss / len(test_loader)\n",
    "    val_acc    = val_correct / val_total\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - {time() - epoch_start:.1f}s | \" \\\n",
    "            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \" \\\n",
    "            f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "    \n",
    "#     # Early stopping\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         no_improve_epochs = 0\n",
    "#         best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "#     else:\n",
    "#         no_improve_epochs += 1\n",
    "#         if no_improve_epochs >= patience:\n",
    "#             print(f\"⏹ Early stopping at epoch {epoch+1} (best val acc {best_val_acc:.4f})\")\n",
    "#             break\n",
    "\n",
    "# # Restore best model\n",
    "# if best_state is not None:\n",
    "#     model.load_state_dict(best_state)\n",
    "\n",
    "# ---------------- Final evaluation ----------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels    = labels.to(device).long()\n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            total_loss += criterion(outputs, labels).item() * raw_batch.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "train_loss, train_acc = evaluate(model, train_loader)\n",
    "test_loss,  test_acc  = evaluate(model, test_loader)\n",
    "\n",
    "print('Final Results:')\n",
    "print(f'Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}')\n",
    "print(f'Test loss: {test_loss:.4f}, accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50245f3-2277-4480-89ec-81a9193bf58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE CLASS PERFORMANCE (9 classes) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_0     0.6250    0.7143    0.6667        21\n",
      "     Class_3     0.8462    0.8800    0.8627        25\n",
      "     Class_4     0.8125    0.6190    0.7027        21\n",
      "     Class_5     0.8500    0.8947    0.8718        19\n",
      "     Class_6     0.9286    0.8125    0.8667        16\n",
      "     Class_7     0.6667    0.8889    0.7619         9\n",
      "     Class_8     0.6667    0.6000    0.6316        10\n",
      "\n",
      "    accuracy                         0.7769       121\n",
      "   macro avg     0.7708    0.7728    0.7663       121\n",
      "weighted avg     0.7852    0.7769    0.7763       121\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_complete_class_performance(model, loader, all_classes=[0, 3, 4, 5, 6, 7, 8]):\n",
    "    \"\"\"Analyze performance for ALL classes the model outputs\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Use ALL classes that the model can predict (9 classes)\n",
    "    # not just the ones that appear in this particular batch\n",
    "    class_names = [f'Class_{i}' for i in all_classes]\n",
    "    \n",
    "    print(\"=== COMPLETE CLASS PERFORMANCE (9 classes) ===\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                               labels=all_classes,  # Force include all 9 classes\n",
    "                               target_names=class_names, \n",
    "                               digits=4,\n",
    "                               zero_division=0))  # Handle classes with no samples\n",
    "    \n",
    "    # Confusion matrix for all classes\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=all_classes)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix (All 9 Classes)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # return all_preds, all_labels\n",
    "\n",
    "# Run the complete analysis with ALL 9 classes\n",
    "all_classes = [0, 3, 4, 5, 6, 7, 8]  # Your actual class labels\n",
    "analyze_complete_class_performance(model, test_loader, all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ff4d1b-b51c-4425-9286-ef461b4224c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 8 errors: 4\n",
      "Class 8 is most often confused with:\n",
      "  Class 7: 1 times\n",
      "  Class 0: 1 times\n",
      "  Class 5: 1 times\n",
      "  Class 3: 1 times\n"
     ]
    }
   ],
   "source": [
    "def analyze_class_8_errors(model, loader):\n",
    "    \"\"\"Targeted analysis for Class 8\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            \n",
    "            for i in range(len(labels_cpu)):\n",
    "                if labels_cpu[i] == 8 and preds_cpu[i] != 8:\n",
    "                    errors.append({\n",
    "                        'true': 8,\n",
    "                        'predicted': preds_cpu[i],\n",
    "                        'confidence': F.softmax(outputs[i], dim=0)[preds[i]].item()\n",
    "                    })\n",
    "    \n",
    "    print(f\"Class 8 errors: {len(errors)}\")\n",
    "    \n",
    "    from collections import Counter\n",
    "    confusion_counts = Counter([error['predicted'] for error in errors])\n",
    "    print(\"Class 8 is most often confused with:\")\n",
    "    for pred_class, count in confusion_counts.most_common():\n",
    "        print(f\"  Class {pred_class}: {count} times\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "class_8_errors = analyze_class_8_errors(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212277e-8433-4ee9-b711-1dc63da70502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------- Data ----------------\n",
    "with open(f\"{DATAFILES_DIR}/compressed_label_map.json\", 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "train_dataset = WideNormalizationIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/train_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    noise_level=0.001,\n",
    "    # window_length=128,\n",
    "    # stride=32,          # lots of windows\n",
    "    add_noise=True      # enable training-time augmentation\n",
    ")\n",
    "test_dataset = WideNormalizationIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/test_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    # window_length=128,\n",
    "    # stride=32,   # lots of windows\n",
    "    add_noise=False\n",
    ")\n",
    "\n",
    "# Compute global stats on TRAIN ONLY, then share with TEST\n",
    "train_dataset.compute_global_stats()\n",
    "test_dataset.global_mean = train_dataset.global_mean.clone()\n",
    "test_dataset.global_std  = train_dataset.global_std.clone()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=0, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "sample_raw, sample_psd, _ = train_dataset[0]\n",
    "num_channels = sample_raw.shape[0]\n",
    "psd_bins = sample_psd.shape[1]\n",
    "num_classes = len(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84e1c7b6-8b94-400e-b2b6-26de1a55be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiments...\n",
      "Running experiment 0/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m optimizer = Adam(model.parameters(), lr=lr, weight_decay=wd)\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Train quickly for 10 epochs to compare\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m acc = train_and_evaluate(model, optimizer, train_loader, test_loader, epochs=\u001b[32m50\u001b[39m)\n\u001b[32m     84\u001b[39m accuracies.append(acc)\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m#print(f'Processed experiment with learning rate: {lr}, dropout: {dropout}, and weight decay: {wd}. Experiment Accuracy: {acc:.4f}')\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mtrain_and_evaluate\u001b[39m\u001b[34m(model, optimizer, train_loader, test_loader, epochs)\u001b[39m\n\u001b[32m     28\u001b[39m     loss.backward()\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# gradient clipping for stability\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m     31\u001b[39m     optimizer.step()\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Initialize local pred and labels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/CS481-env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:38\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/CS481-env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:220\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    218\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    219\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/CS481-env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:38\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/CS481-env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:176\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    174\u001b[39m clip_coef_clamped_device = clip_coef_clamped.to(device)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m device_grads:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     g.mul_(clip_coef_clamped_device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_and_evaluate(model, optimizer, train_loader, test_loader, epochs=50):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # All Evaluation predictions and targets\n",
    "    all_accuracy = []\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for raw_batch, psd_batch, labels in train_loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels    = labels.to(device).long()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Initialize local pred and labels\n",
    "        preds = []\n",
    "        targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for raw_batch, psd_batch, labels in test_loader:\n",
    "                raw_batch = raw_batch.to(device)\n",
    "                psd_batch = psd_batch.to(device)\n",
    "                labels    = labels.to(device).long()\n",
    "                \n",
    "                outputs = model(raw_batch, psd_batch)\n",
    "                pred = outputs.argmax(dim=1)\n",
    "                \n",
    "                preds.extend(pred.cpu().numpy())\n",
    "                targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(targets, preds)\n",
    "        all_accuracy.append(accuracy)\n",
    "        # Early stopping check\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_weights = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 5:  # 5 epochs no improvement\n",
    "                break\n",
    "\n",
    "    return best_acc\n",
    "\n",
    "# Your grid search code (you'll need to define train_loader and val_loader)\n",
    "learning_rates = [1e-4, 3e-4, 1e-3, 3e-3]\n",
    "dropout_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "weight_decays = [0, 1e-5, 1e-4, 1e-3]\n",
    "\n",
    "best_acc = 0\n",
    "best_params = {}\n",
    "accuracies = []\n",
    "results = []\n",
    "\n",
    "print('Starting experiments...')\n",
    "for instance in range(101):\n",
    "    print(f'Running experiment {instance}/100')\n",
    "    for lr in learning_rates:\n",
    "        for dropout in dropout_rates:\n",
    "            for wd in weight_decays:\n",
    "                model = SimpleIMUSonarNet(num_channels=8, num_classes=num_classes, psd_bins=psd_bins, dropout=dropout)\n",
    "                optimizer = Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "                # Train quickly for 10 epochs to compare\n",
    "                acc = train_and_evaluate(model, optimizer, train_loader, test_loader, epochs=50)\n",
    "                accuracies.append(acc)\n",
    "                #print(f'Processed experiment with learning rate: {lr}, dropout: {dropout}, and weight decay: {wd}. Experiment Accuracy: {acc:.4f}')\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_params = {'lr': lr, 'dropout': dropout, 'weight_decay': wd}\n",
    "    # Capture instance info\n",
    "    results.append({\n",
    "        'mean': np.mean(accuracies),\n",
    "        'std': np.std(accuracies),\n",
    "        'max': np.max(accuracies),\n",
    "        'min': np.min(accuracies),\n",
    "        'params': best_params,\n",
    "        'accuracy': best_acc\n",
    "    })\n",
    "best = {}\n",
    "for instance in results:\n",
    "    if best is None: best = instance\n",
    "    elif instance['accuracy'] > best['accuracy']: best = instance\n",
    "\n",
    "print(f\"For 100 experiments - Best params: {instance['params']}, Accuracy: {instance['accuracy']:.3f}\")\n",
    "# print(f\"Best params: {best_params}, Accuracy: {best_acc:.3f}\")\n",
    "# print(f\"{results['params']}: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc5375d2-207d-4894-b01a-98cf763bade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current best configuration\n",
    "best_lr = 0.0003  # From your latest test\n",
    "best_dropout = 0.2  # From grid search\n",
    "best_wd = 0.001     # From grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98b2c605-e440-4fe9-aa94-eeb6eaf4157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "LR 0.0003: 0.752\n",
      "LR 0.00032: 0.785\n",
      "LR 0.00035: 0.769\n",
      "LR 0.00038: 0.769\n",
      "LR 0.0004: 0.719\n"
     ]
    }
   ],
   "source": [
    "# Test around your best LR\n",
    "fine_tune_lrs = [0.0003, 0.00032, 0.00035, 0.00038, 0.0004]\n",
    "for lr in fine_tune_lrs:\n",
    "    # Quick test with your best dropout and weight decay\n",
    "    model = SimpleIMUSonarNet(num_channels=8, num_classes=num_classes, psd_bins=psd_bins, dropout=best_dropout)\n",
    "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=best_wd)\n",
    "    acc = train_and_evaluate(model, optimizer, train_loader, test_loader, epochs=50)\n",
    "    print(f\"LR {lr}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68472ffd-c7d5-43df-b52c-6c66d5c3d119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ed6bc9-0b69-45b8-9892-76bf4f2cab21",
   "metadata": {},
   "source": [
    "# Additional Feature extraction\n",
    "The dataset will extract additional features to assist with training correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ce4196f2-a935-463c-bda2-18b8d3deab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import welch\n",
    "\n",
    "class WideNormFeatureExtractIMUSonarFromJSON(WideNormalizationIMUSonarFromJSON):\n",
    "    \"\"\"Dataset for IMU + Ultrasonic with raw + PSD output and feature extraction support\"\"\"\n",
    "\n",
    "    def _extract_features(self, data):\n",
    "        \"\"\"Extract meaningful features from normalized sensor data with robustness\"\"\"\n",
    "        if torch.is_tensor(data):\n",
    "            data = data.numpy()\n",
    "        \n",
    "        C, T = data.shape\n",
    "        features = []\n",
    "        \n",
    "        # 1. Basic statistical features per channel (with robustness)\n",
    "        for ch in range(C):\n",
    "            channel_data = data[ch]\n",
    "            \n",
    "            # Basic stats that are always safe\n",
    "            channel_features = [\n",
    "                np.mean(channel_data),      # DC offset\n",
    "                np.std(channel_data),       # Variability\n",
    "                np.max(channel_data),       # Peak amplitude\n",
    "                np.min(channel_data),       # Minimum amplitude\n",
    "                np.ptp(channel_data),       # Peak-to-peak\n",
    "            ]\n",
    "            \n",
    "            # Robust skewness and kurtosis calculation\n",
    "            if np.std(channel_data) > 1e-6:  # Only calculate if there's variation\n",
    "                try:\n",
    "                    channel_features.append(skew(channel_data))\n",
    "                except:\n",
    "                    channel_features.append(0.0)  # Fallback for skewness\n",
    "                \n",
    "                try:\n",
    "                    channel_features.append(kurtosis(channel_data))\n",
    "                except:\n",
    "                    channel_features.append(0.0)  # Fallback for kurtosis\n",
    "            else:\n",
    "                channel_features.extend([0.0, 0.0])  # No variation = symmetric, normal\n",
    "                \n",
    "            features.extend(channel_features)\n",
    "        \n",
    "        # 2. Cross-sensor correlation features (with robustness)\n",
    "        # Accelerometer correlations\n",
    "        if np.any(np.std(data[0:3], axis=1) > 1e-6):  # Check if any accel channel has variation\n",
    "            try:\n",
    "                accel_corr = np.corrcoef(data[0:3])\n",
    "                features.extend([accel_corr[0,1], accel_corr[0,2], accel_corr[1,2]])\n",
    "            except:\n",
    "                features.extend([0.0, 0.0, 0.0])\n",
    "        else:\n",
    "            features.extend([0.0, 0.0, 0.0])\n",
    "        \n",
    "        # Gyroscope correlations\n",
    "        if np.any(np.std(data[3:6], axis=1) > 1e-6):\n",
    "            try:\n",
    "                gyro_corr = np.corrcoef(data[3:6])\n",
    "                features.extend([gyro_corr[0,1], gyro_corr[0,2], gyro_corr[1,2]])\n",
    "            except:\n",
    "                features.extend([0.0, 0.0, 0.0])\n",
    "        else:\n",
    "            features.extend([0.0, 0.0, 0.0])\n",
    "        \n",
    "        # 3. Time-domain features for movement characterization\n",
    "        for ch in range(6):  # For IMU channels only\n",
    "            channel_data = data[ch]\n",
    "            if len(channel_data) > 1 and np.std(channel_data) > 1e-6:\n",
    "                derivatives = np.diff(channel_data)\n",
    "                features.extend([\n",
    "                    np.mean(np.abs(derivatives)),    # Average movement intensity\n",
    "                    np.std(derivatives),             # Movement variability\n",
    "                    (np.abs(derivatives) > 0.1).mean(),  # Proportion of significant movements\n",
    "                ])\n",
    "            else:\n",
    "                features.extend([0.0, 0.0, 0.0])\n",
    "        \n",
    "        # 4. Sonar-specific features\n",
    "        for ch in range(6, 8):  # For sonar channels\n",
    "            channel_data = data[ch]\n",
    "            if len(channel_data) > 0:\n",
    "                median_val = np.median(channel_data)\n",
    "                features.extend([\n",
    "                    median_val,         # Typical distance\n",
    "                    (channel_data > median_val + 0.5).mean(),  # Far events\n",
    "                    (channel_data < median_val - 0.5).mean(),  # Near events\n",
    "                ])\n",
    "            else:\n",
    "                features.extend([0.0, 0.0, 0.0])\n",
    "        \n",
    "        # 5. Cross-modal features (IMU + Sonar relationships)\n",
    "        try:\n",
    "            if data.shape[1] > 1:  # Need at least 2 time points for derivatives\n",
    "                avg_movement = np.mean(np.abs(np.diff(data[0:6], axis=1)), axis=0)\n",
    "                sonar_change = np.abs(np.diff(data[6:8], axis=1)).mean(axis=0)\n",
    "                \n",
    "                min_len = min(len(avg_movement), len(sonar_change))\n",
    "                if min_len > 1:\n",
    "                    movement_sonar_corr = np.corrcoef(avg_movement[:min_len], \n",
    "                                                     sonar_change[:min_len])[0,1]\n",
    "                    features.append(movement_sonar_corr if not np.isnan(movement_sonar_corr) else 0.0)\n",
    "                else:\n",
    "                    features.append(0.0)\n",
    "            else:\n",
    "                features.append(0.0)\n",
    "        except:\n",
    "            features.append(0.0)\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # sample_idx, start, end = self.window_index[idx]\n",
    "        item = self.samples[idx]\n",
    "        df = pd.read_csv(item['path'])\n",
    "    \n",
    "        # Resample to get raw data (C, T)\n",
    "        # full_data = self._resample_to_uniform(df)\n",
    "        # data = full_data[:, start:end]  # Slice the window\n",
    "        data = self._resample_to_uniform(df)\n",
    "        \n",
    "        # --- NEW: Add feature extraction here ---\n",
    "        features = self._extract_features(data)\n",
    "        \n",
    "        # Estimate sample frequency for PSD\n",
    "        total_time_sec = (df['Timestamp(ms)'].iloc[-1] - df['Timestamp(ms)'].iloc[0]) / 1000.0\n",
    "        fs_est = self.target_length / total_time_sec if total_time_sec > 0 else 50.0\n",
    "    \n",
    "        # Compute PSD - FIX: data is already numpy, no need for .numpy()\n",
    "        psd = self.compute_psd(data, fs=fs_est)  # REMOVE .numpy() here!\n",
    "    \n",
    "        # Return raw data, PSD, AND the new features\n",
    "        return (torch.tensor(data, dtype=torch.float32), \n",
    "                torch.tensor(psd, dtype=torch.float32), \n",
    "                features, \n",
    "                torch.tensor(item['label'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1c2368c0-6b1c-4df3-97fd-79d9974c07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EnhancedIMUSonarNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced model with three input branches: raw time series, PSD, and engineered features\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels=8, num_classes=7, psd_bins=64, num_engineered_features=50, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Time domain branch ---\n",
    "        self.time_conv = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/3),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/3),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        \n",
    "        # --- PSD branch ---\n",
    "        self.psd_fc = nn.Sequential(\n",
    "            nn.Linear(num_channels * psd_bins, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/2)\n",
    "        )\n",
    "        \n",
    "        # --- Engineered Features branch ---\n",
    "        self.feature_mlp = nn.Sequential(\n",
    "            nn.Linear(num_engineered_features, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout/3)\n",
    "        )\n",
    "        \n",
    "        # --- Fusion and classification ---\n",
    "        # 256 (time) + 128 (PSD) + 64 (features) = 448 total features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 + 128 + 64, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, raw_x, psd_x, features_x):\n",
    "        # Time domain processing\n",
    "        time_features = self.time_conv(raw_x).squeeze(-1)\n",
    "        \n",
    "        # PSD processing\n",
    "        psd_flat = psd_x.view(psd_x.size(0), -1)\n",
    "        psd_features = self.psd_fc(psd_flat)\n",
    "        \n",
    "        # Engineered features processing\n",
    "        feature_features = self.feature_mlp(features_x)\n",
    "        \n",
    "        # Concatenate all three branches and classify\n",
    "        combined = torch.cat([time_features, psd_features, feature_features], dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1ead80cc-0b82-4564-962d-64b0727018d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Input dimensions: 8 channels, 65 PSD bins, 87 engineered features\n",
      "Number of classes: 9\n",
      "Epoch 1/50 - 3.2s | Train Loss: 2.4536 Acc: 0.2549 | Val Loss: 1.6564 Acc: 0.5124\n",
      "Epoch 2/50 - 3.0s | Train Loss: 1.7741 Acc: 0.4706 | Val Loss: 1.3013 Acc: 0.6033\n",
      "Epoch 3/50 - 3.3s | Train Loss: 1.4073 Acc: 0.5809 | Val Loss: 1.2045 Acc: 0.6860\n",
      "Epoch 4/50 - 3.3s | Train Loss: 1.2564 Acc: 0.6176 | Val Loss: 1.1816 Acc: 0.6694\n",
      "Epoch 5/50 - 3.1s | Train Loss: 1.2130 Acc: 0.6348 | Val Loss: 1.1793 Acc: 0.6446\n",
      "Epoch 6/50 - 3.3s | Train Loss: 1.0707 Acc: 0.6961 | Val Loss: 1.2015 Acc: 0.6777\n",
      "Epoch 7/50 - 3.4s | Train Loss: 1.0672 Acc: 0.6912 | Val Loss: 1.1249 Acc: 0.7025\n",
      "Epoch 8/50 - 3.3s | Train Loss: 0.9775 Acc: 0.7426 | Val Loss: 1.1138 Acc: 0.7355\n",
      "Epoch 9/50 - 3.3s | Train Loss: 0.8936 Acc: 0.7647 | Val Loss: 0.9799 Acc: 0.7603\n",
      "Epoch 10/50 - 3.1s | Train Loss: 0.8128 Acc: 0.7917 | Val Loss: 1.1193 Acc: 0.7107\n",
      "Epoch 11/50 - 3.1s | Train Loss: 0.8354 Acc: 0.7868 | Val Loss: 0.9964 Acc: 0.7273\n",
      "Epoch 12/50 - 3.3s | Train Loss: 0.7567 Acc: 0.8113 | Val Loss: 1.0471 Acc: 0.7355\n",
      "Epoch 13/50 - 3.3s | Train Loss: 0.7177 Acc: 0.8113 | Val Loss: 1.0215 Acc: 0.7190\n",
      "Epoch 14/50 - 3.2s | Train Loss: 0.7201 Acc: 0.8358 | Val Loss: 0.9666 Acc: 0.7107\n",
      "Epoch 15/50 - 3.2s | Train Loss: 0.6330 Acc: 0.8529 | Val Loss: 0.9993 Acc: 0.7438\n",
      "Epoch 16/50 - 3.3s | Train Loss: 0.6743 Acc: 0.8407 | Val Loss: 0.9765 Acc: 0.7769\n",
      "Epoch 17/50 - 3.2s | Train Loss: 0.6912 Acc: 0.8480 | Val Loss: 0.9784 Acc: 0.7769\n",
      "Epoch 18/50 - 3.2s | Train Loss: 0.6176 Acc: 0.8627 | Val Loss: 1.0303 Acc: 0.7438\n",
      "Epoch 19/50 - 3.1s | Train Loss: 0.6145 Acc: 0.8848 | Val Loss: 0.9389 Acc: 0.7521\n",
      "Epoch 20/50 - 3.1s | Train Loss: 0.6103 Acc: 0.8799 | Val Loss: 0.9220 Acc: 0.7521\n",
      "Epoch 21/50 - 3.2s | Train Loss: 0.5461 Acc: 0.9216 | Val Loss: 0.9039 Acc: 0.7686\n",
      "Epoch 22/50 - 3.1s | Train Loss: 0.5477 Acc: 0.9240 | Val Loss: 0.9343 Acc: 0.7686\n",
      "Epoch 23/50 - 3.3s | Train Loss: 0.5290 Acc: 0.9167 | Val Loss: 0.9102 Acc: 0.7686\n",
      "Epoch 24/50 - 3.4s | Train Loss: 0.4926 Acc: 0.9314 | Val Loss: 0.9369 Acc: 0.7686\n",
      "Epoch 25/50 - 3.4s | Train Loss: 0.5613 Acc: 0.8995 | Val Loss: 0.9910 Acc: 0.7273\n",
      "Epoch 26/50 - 3.2s | Train Loss: 0.5235 Acc: 0.9265 | Val Loss: 0.9311 Acc: 0.7603\n",
      "Epoch 27/50 - 3.1s | Train Loss: 0.4996 Acc: 0.9363 | Val Loss: 0.9062 Acc: 0.7686\n",
      "Epoch 28/50 - 3.1s | Train Loss: 0.5026 Acc: 0.9167 | Val Loss: 0.8862 Acc: 0.7686\n",
      "Epoch 29/50 - 3.0s | Train Loss: 0.5365 Acc: 0.9142 | Val Loss: 0.9000 Acc: 0.7686\n",
      "Epoch 30/50 - 3.0s | Train Loss: 0.4899 Acc: 0.9338 | Val Loss: 0.9241 Acc: 0.7521\n",
      "Epoch 31/50 - 3.0s | Train Loss: 0.5041 Acc: 0.9216 | Val Loss: 0.9318 Acc: 0.7686\n",
      "Epoch 32/50 - 3.1s | Train Loss: 0.4967 Acc: 0.9191 | Val Loss: 0.9307 Acc: 0.7686\n",
      "Epoch 33/50 - 3.2s | Train Loss: 0.4985 Acc: 0.9314 | Val Loss: 0.9403 Acc: 0.7521\n",
      "Epoch 34/50 - 3.2s | Train Loss: 0.5011 Acc: 0.9338 | Val Loss: 0.9286 Acc: 0.7603\n",
      "Epoch 35/50 - 3.2s | Train Loss: 0.5076 Acc: 0.9191 | Val Loss: 0.9558 Acc: 0.7603\n",
      "Epoch 36/50 - 3.3s | Train Loss: 0.4737 Acc: 0.9412 | Val Loss: 0.9718 Acc: 0.7521\n",
      "Epoch 37/50 - 3.2s | Train Loss: 0.4837 Acc: 0.9412 | Val Loss: 0.9644 Acc: 0.7603\n",
      "Epoch 38/50 - 3.7s | Train Loss: 0.4925 Acc: 0.9314 | Val Loss: 0.9114 Acc: 0.7686\n",
      "Epoch 39/50 - 3.4s | Train Loss: 0.4399 Acc: 0.9412 | Val Loss: 0.9393 Acc: 0.7686\n",
      "Epoch 40/50 - 3.5s | Train Loss: 0.4951 Acc: 0.9216 | Val Loss: 0.9245 Acc: 0.7686\n",
      "Epoch 41/50 - 3.1s | Train Loss: 0.4823 Acc: 0.9338 | Val Loss: 0.9220 Acc: 0.7686\n",
      "Epoch 42/50 - 3.4s | Train Loss: 0.5083 Acc: 0.9216 | Val Loss: 0.9957 Acc: 0.7603\n",
      "Epoch 43/50 - 3.3s | Train Loss: 0.4500 Acc: 0.9559 | Val Loss: 0.9147 Acc: 0.7769\n",
      "Epoch 44/50 - 3.0s | Train Loss: 0.4656 Acc: 0.9461 | Val Loss: 0.9206 Acc: 0.7686\n",
      "Epoch 45/50 - 3.0s | Train Loss: 0.4451 Acc: 0.9608 | Val Loss: 0.9270 Acc: 0.7769\n",
      "Epoch 46/50 - 3.1s | Train Loss: 0.4375 Acc: 0.9608 | Val Loss: 0.9329 Acc: 0.7769\n",
      "Epoch 47/50 - 3.3s | Train Loss: 0.4764 Acc: 0.9338 | Val Loss: 0.9236 Acc: 0.7686\n",
      "Epoch 48/50 - 3.4s | Train Loss: 0.4843 Acc: 0.9436 | Val Loss: 0.9294 Acc: 0.7686\n",
      "Epoch 49/50 - 3.4s | Train Loss: 0.4553 Acc: 0.9681 | Val Loss: 0.9224 Acc: 0.7686\n",
      "Epoch 50/50 - 3.1s | Train Loss: 0.4767 Acc: 0.9412 | Val Loss: 0.9219 Acc: 0.7769\n",
      "Final Results:\n",
      "Train loss: 0.3500, accuracy: 0.9951\n",
      "Test loss: 0.9020, accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------- Data ----------------\n",
    "with open(f\"{DATAFILES_DIR}/compressed_label_map.json\", 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "train_dataset = WideNormFeatureExtractIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/train_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    add_noise=False  # No augmentation since we're using engineered features\n",
    ")\n",
    "test_dataset = WideNormFeatureExtractIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/test_split.json\", \n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    add_noise=False\n",
    ")\n",
    "\n",
    "# Compute global stats on TRAIN ONLY, then share with TEST\n",
    "train_dataset.compute_global_stats()\n",
    "test_dataset.global_mean = train_dataset.global_mean.clone()\n",
    "test_dataset.global_std  = train_dataset.global_std.clone()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=0, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "# Get sample to determine feature dimensions\n",
    "sample_raw, sample_psd, sample_features, _ = train_dataset[0]\n",
    "num_channels = sample_raw.shape[0]\n",
    "psd_bins = sample_psd.shape[1]\n",
    "num_engineered_features = sample_features.shape[0]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "print(f\"Input dimensions: {num_channels} channels, {psd_bins} PSD bins, {num_engineered_features} engineered features\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "model = EnhancedIMUSonarNet(\n",
    "    num_channels=num_channels,\n",
    "    num_classes=num_classes,\n",
    "    psd_bins=psd_bins,\n",
    "    num_engineered_features=num_engineered_features,\n",
    "    dropout=0.3  # Slightly higher dropout for the larger model\n",
    ").to(device)\n",
    "\n",
    "# ---------------- Train loop ----------------\n",
    "epochs = 50\n",
    "\n",
    "# # Compute class weights on training data\n",
    "# train_dataset.compute_class_stats()\n",
    "# # Use the computed weights in your loss function\n",
    "# criterion = nn.CrossEntropyLoss(\n",
    "#     weight=train_dataset.class_weights.to(device), \n",
    "#     label_smoothing=0.05\n",
    "# )\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # Reduced weight decay\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0.0\n",
    "patience = 5\n",
    "no_improve_epochs = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    epoch_start = time()\n",
    "    \n",
    "    for raw_batch, psd_batch, features_batch, labels in train_loader:\n",
    "        raw_batch = raw_batch.to(device)\n",
    "        psd_batch = psd_batch.to(device)\n",
    "        features_batch = features_batch.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(raw_batch, psd_batch, features_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, features_batch, labels in test_loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch, features_batch)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total   += labels.size(0)\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc  = correct / total\n",
    "    val_loss   = val_loss / len(test_loader)\n",
    "    val_acc    = val_correct / val_total\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - {time() - epoch_start:.1f}s | \" \\\n",
    "            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \" \\\n",
    "            f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # # Early stopping\n",
    "    # if val_acc > best_val_acc:\n",
    "    #     best_val_acc = val_acc\n",
    "    #     no_improve_epochs = 0\n",
    "    #     best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "    # else:\n",
    "    #     no_improve_epochs += 1\n",
    "    #     if no_improve_epochs >= patience:\n",
    "    #         print(f\"⏹ Early stopping at epoch {epoch+1} (best val acc {best_val_acc:.4f})\")\n",
    "    #         break\n",
    "\n",
    "# # Restore best model\n",
    "# if best_state is not None:\n",
    "#     model.load_state_dict(best_state)\n",
    "\n",
    "# ---------------- Final evaluation ----------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, features_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch, features_batch)\n",
    "            total_loss += criterion(outputs, labels).item() * raw_batch.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "train_loss, train_acc = evaluate(model, train_loader)\n",
    "test_loss,  test_acc  = evaluate(model, test_loader)\n",
    "\n",
    "print('Final Results:')\n",
    "print(f'Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}')\n",
    "print(f'Test loss: {test_loss:.4f}, accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf76b4-ec72-414a-9a87-bfe5a6760d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcb60d66-1028-4858-9e3e-382e3334d388",
   "metadata": {},
   "source": [
    "# Weighted Class Dataset Training\n",
    "This will create weights for unbalanced classes (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2640abdc-a05e-4abb-8dac-aceb0d5b4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import welch\n",
    "\n",
    "class WideNormWeightedClassesIMUSonarFromJSON(WideNormalizationIMUSonarFromJSON):\n",
    "    \"\"\"Dataset for IMU + Ultrasonic with raw + PSD output and class weighting support\"\"\"\n",
    "\n",
    "    def __init__(self, json_file, label_map=None, transform=None, target_length=600, debug=False, add_noise=False, noise_level=0.01):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.samples = json.load(f)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.label_map = {v: k for k, v in label_map.items()} if label_map else {}\n",
    "        self.target_length = target_length\n",
    "        self.debug = debug\n",
    "        self.add_noise = add_noise\n",
    "        self.noise_level = noise_level\n",
    "        self.cols = IMUSonarFromJSON.cols\n",
    "\n",
    "        # Initialize class statistics\n",
    "        self.class_counts = None\n",
    "        self.class_weights = None\n",
    "\n",
    "    def compute_class_stats(self):\n",
    "        \"\"\"Compute class distribution and weights for imbalanced data, including empty classes\"\"\"\n",
    "        # Define ALL 9 classes in your labeling system (including empty ones)\n",
    "        all_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8]  # Your complete 9-class system\n",
    "        num_classes = len(all_classes)\n",
    "        \n",
    "        # Count samples per class (empty classes will have 0)\n",
    "        class_counts = torch.zeros(num_classes)\n",
    "        for item in self.samples:\n",
    "            label = item['label']\n",
    "            if label in all_classes:\n",
    "                class_index = all_classes.index(label)\n",
    "                class_counts[class_index] += 1\n",
    "            else:\n",
    "                print(f\"Warning: Label {label} not in expected class system\")\n",
    "        \n",
    "        self.class_counts = class_counts\n",
    "        \n",
    "        # Compute class weights - handle empty classes carefully\n",
    "        # For empty classes, use a reasonable default weight (e.g., average weight)\n",
    "        non_zero_counts = class_counts[class_counts > 0]\n",
    "        if len(non_zero_counts) > 0:\n",
    "            default_weight = 1.0 / (non_zero_counts.float().mean() + 1e-6)\n",
    "        else:\n",
    "            default_weight = 1.0\n",
    "        \n",
    "        self.class_weights = torch.where(\n",
    "            class_counts > 0,\n",
    "            1.0 / (class_counts.float() + 1e-6),  # Inverse frequency for non-empty classes\n",
    "            torch.full_like(class_counts.float(), default_weight)  # Default for empty classes\n",
    "        )\n",
    "        \n",
    "        # Normalize weights\n",
    "        self.class_weights = self.class_weights / self.class_weights.sum()\n",
    "        \n",
    "        print(\"Class distribution (9-class system):\")\n",
    "        for i, class_label in enumerate(all_classes):\n",
    "            status = \"EMPTY\" if class_counts[i] == 0 else \"HAS SAMPLES\"\n",
    "            print(f\"Class {class_label}: {class_counts[i]} samples, weight: {self.class_weights[i]:.6f} ({status})\")\n",
    "        \n",
    "        return self.class_weights\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return (raw_tensor, psd_tensor, label)\"\"\"\n",
    "        item = self.samples[idx]\n",
    "        df = pd.read_csv(item['path'])\n",
    "\n",
    "        # Resample to uniform shape (C, T)\n",
    "        data = self._resample_to_uniform(df)\n",
    "\n",
    "        # Estimate sample frequency for PSD\n",
    "        total_time_sec = (df['Timestamp(ms)'].iloc[-1] - df['Timestamp(ms)'].iloc[0]) / 1000.0\n",
    "        fs_est = self.target_length / total_time_sec if total_time_sec > 0 else 50.0\n",
    "\n",
    "        # Compute PSD (C, F)\n",
    "        psd = self.compute_psd(data, fs=fs_est)\n",
    "\n",
    "        # Convert to tensors\n",
    "        if isinstance(data, np.ndarray): \n",
    "            raw_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "        else: \n",
    "            raw_tensor = data\n",
    "        psd_tensor = torch.tensor(psd, dtype=torch.float32)\n",
    "\n",
    "        label = self.label_map[item['label']] if self.label_map else item['label']\n",
    "        label_tensor = torch.tensor(item['label'], dtype=torch.long)\n",
    "\n",
    "        return raw_tensor, psd_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e19a5bc9-6d1a-4fae-bfa6-81f4c26444e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Input dimensions: 8 channels, 65 PSD bins, 87 engineered features\n",
      "Number of classes: 9\n",
      "Class distribution (9-class system):\n",
      "Class 0: 81.0 samples, weight: 0.072852 (HAS SAMPLES)\n",
      "Class 1: 0.0 samples, weight: 0.101243 (EMPTY)\n",
      "Class 2: 0.0 samples, weight: 0.101243 (EMPTY)\n",
      "Class 3: 80.0 samples, weight: 0.073763 (HAS SAMPLES)\n",
      "Class 4: 64.0 samples, weight: 0.092204 (HAS SAMPLES)\n",
      "Class 5: 64.0 samples, weight: 0.092204 (HAS SAMPLES)\n",
      "Class 6: 52.0 samples, weight: 0.113482 (HAS SAMPLES)\n",
      "Class 7: 32.0 samples, weight: 0.184408 (HAS SAMPLES)\n",
      "Class 8: 35.0 samples, weight: 0.168601 (HAS SAMPLES)\n",
      "Epoch 1/50 - 1.5s | Train Loss: 2.4807 Acc: 0.2304 | Val Loss: 1.7758 Acc: 0.3719\n",
      "Epoch 2/50 - 1.4s | Train Loss: 1.7939 Acc: 0.4608 | Val Loss: 1.4196 Acc: 0.5289\n",
      "Epoch 3/50 - 1.4s | Train Loss: 1.4504 Acc: 0.5466 | Val Loss: 1.2920 Acc: 0.6364\n",
      "Epoch 4/50 - 1.4s | Train Loss: 1.2977 Acc: 0.6275 | Val Loss: 1.2144 Acc: 0.6529\n",
      "Epoch 5/50 - 1.4s | Train Loss: 1.2394 Acc: 0.6422 | Val Loss: 1.1389 Acc: 0.6777\n",
      "Epoch 6/50 - 1.5s | Train Loss: 1.0984 Acc: 0.6936 | Val Loss: 1.1734 Acc: 0.6777\n",
      "Epoch 7/50 - 1.4s | Train Loss: 1.0764 Acc: 0.6912 | Val Loss: 1.1748 Acc: 0.6777\n",
      "Epoch 8/50 - 1.4s | Train Loss: 1.0440 Acc: 0.6985 | Val Loss: 1.1262 Acc: 0.7190\n",
      "Epoch 9/50 - 1.4s | Train Loss: 0.9990 Acc: 0.7328 | Val Loss: 1.0015 Acc: 0.7355\n",
      "Epoch 10/50 - 1.4s | Train Loss: 0.8917 Acc: 0.7647 | Val Loss: 1.0678 Acc: 0.7190\n",
      "Epoch 11/50 - 1.4s | Train Loss: 0.8743 Acc: 0.7672 | Val Loss: 1.2043 Acc: 0.6942\n",
      "Epoch 12/50 - 1.4s | Train Loss: 0.8649 Acc: 0.7770 | Val Loss: 1.0885 Acc: 0.7438\n",
      "Epoch 13/50 - 1.4s | Train Loss: 0.7714 Acc: 0.8113 | Val Loss: 1.0183 Acc: 0.7355\n",
      "Epoch 14/50 - 1.4s | Train Loss: 0.7257 Acc: 0.8211 | Val Loss: 0.9745 Acc: 0.7355\n",
      "Epoch 15/50 - 1.4s | Train Loss: 0.7664 Acc: 0.8260 | Val Loss: 0.9993 Acc: 0.7273\n",
      "Epoch 16/50 - 1.4s | Train Loss: 0.7510 Acc: 0.8456 | Val Loss: 1.0005 Acc: 0.7603\n",
      "Epoch 17/50 - 1.4s | Train Loss: 0.6992 Acc: 0.8505 | Val Loss: 0.9736 Acc: 0.7355\n",
      "Epoch 18/50 - 1.4s | Train Loss: 0.6313 Acc: 0.8505 | Val Loss: 0.9529 Acc: 0.7355\n",
      "Epoch 19/50 - 1.4s | Train Loss: 0.6138 Acc: 0.8824 | Val Loss: 0.9521 Acc: 0.7686\n",
      "Epoch 20/50 - 1.4s | Train Loss: 0.5882 Acc: 0.9093 | Val Loss: 0.9289 Acc: 0.7851\n",
      "Epoch 21/50 - 1.4s | Train Loss: 0.6328 Acc: 0.8652 | Val Loss: 0.9464 Acc: 0.7438\n",
      "Epoch 22/50 - 1.4s | Train Loss: 0.5894 Acc: 0.8873 | Val Loss: 0.9821 Acc: 0.7521\n",
      "Epoch 23/50 - 1.4s | Train Loss: 0.5956 Acc: 0.8971 | Val Loss: 0.9728 Acc: 0.7521\n",
      "Epoch 24/50 - 1.4s | Train Loss: 0.6155 Acc: 0.8701 | Val Loss: 0.9451 Acc: 0.7851\n",
      "Epoch 25/50 - 1.4s | Train Loss: 0.5665 Acc: 0.9118 | Val Loss: 0.9436 Acc: 0.7686\n",
      "Epoch 26/50 - 1.4s | Train Loss: 0.5652 Acc: 0.8848 | Val Loss: 0.9526 Acc: 0.7521\n",
      "Epoch 27/50 - 1.4s | Train Loss: 0.5287 Acc: 0.9289 | Val Loss: 1.0164 Acc: 0.7603\n",
      "Epoch 28/50 - 1.4s | Train Loss: 0.5594 Acc: 0.8995 | Val Loss: 0.9652 Acc: 0.7521\n",
      "Epoch 29/50 - 1.4s | Train Loss: 0.5398 Acc: 0.9069 | Val Loss: 0.9720 Acc: 0.7603\n",
      "Epoch 30/50 - 1.4s | Train Loss: 0.5632 Acc: 0.9191 | Val Loss: 0.9658 Acc: 0.7769\n",
      "Epoch 31/50 - 1.4s | Train Loss: 0.5327 Acc: 0.9167 | Val Loss: 0.9807 Acc: 0.7851\n",
      "Epoch 32/50 - 1.4s | Train Loss: 0.5258 Acc: 0.9142 | Val Loss: 0.9614 Acc: 0.7603\n",
      "Epoch 33/50 - 1.4s | Train Loss: 0.5543 Acc: 0.9069 | Val Loss: 0.9711 Acc: 0.7521\n",
      "Epoch 34/50 - 1.4s | Train Loss: 0.5356 Acc: 0.9289 | Val Loss: 0.9674 Acc: 0.7686\n",
      "Epoch 35/50 - 1.4s | Train Loss: 0.4937 Acc: 0.9510 | Val Loss: 0.9601 Acc: 0.7769\n",
      "Epoch 36/50 - 1.5s | Train Loss: 0.5563 Acc: 0.9044 | Val Loss: 0.9725 Acc: 0.7603\n",
      "Epoch 37/50 - 1.6s | Train Loss: 0.4786 Acc: 0.9485 | Val Loss: 0.9661 Acc: 0.7769\n",
      "Epoch 38/50 - 1.5s | Train Loss: 0.5540 Acc: 0.9069 | Val Loss: 0.9624 Acc: 0.7851\n",
      "Epoch 39/50 - 1.5s | Train Loss: 0.4958 Acc: 0.9387 | Val Loss: 0.9543 Acc: 0.7934\n",
      "Epoch 40/50 - 1.5s | Train Loss: 0.4864 Acc: 0.9387 | Val Loss: 0.9388 Acc: 0.7851\n",
      "Epoch 41/50 - 1.5s | Train Loss: 0.5068 Acc: 0.9461 | Val Loss: 0.9586 Acc: 0.7686\n",
      "Epoch 42/50 - 1.5s | Train Loss: 0.4969 Acc: 0.9412 | Val Loss: 0.9544 Acc: 0.7851\n",
      "Epoch 43/50 - 1.4s | Train Loss: 0.4716 Acc: 0.9436 | Val Loss: 0.9594 Acc: 0.7851\n",
      "Epoch 44/50 - 1.5s | Train Loss: 0.4923 Acc: 0.9363 | Val Loss: 0.9701 Acc: 0.7686\n",
      "Epoch 45/50 - 1.5s | Train Loss: 0.5293 Acc: 0.9436 | Val Loss: 0.9660 Acc: 0.7769\n",
      "Epoch 46/50 - 1.4s | Train Loss: 0.5099 Acc: 0.9216 | Val Loss: 0.9519 Acc: 0.7851\n",
      "Epoch 47/50 - 1.5s | Train Loss: 0.5220 Acc: 0.9314 | Val Loss: 0.9515 Acc: 0.7769\n",
      "Epoch 48/50 - 1.5s | Train Loss: 0.5011 Acc: 0.9412 | Val Loss: 0.9591 Acc: 0.7603\n",
      "Epoch 49/50 - 1.4s | Train Loss: 0.4815 Acc: 0.9363 | Val Loss: 0.9707 Acc: 0.7686\n",
      "Epoch 50/50 - 1.4s | Train Loss: 0.5091 Acc: 0.9289 | Val Loss: 0.9615 Acc: 0.7603\n",
      "Final Results:\n",
      "Train loss: 0.3789, accuracy: 0.9902\n",
      "Test loss: 0.9379, accuracy: 0.7603\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------- Data ----------------\n",
    "with open(f\"{DATAFILES_DIR}/compressed_label_map.json\", 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "train_dataset = WideNormWeightedClassesIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/train_split.json\",\n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    noise_level=0.001,\n",
    "    add_noise=True  # No augmentation since we're using engineered features\n",
    ")\n",
    "test_dataset = WideNormWeightedClassesIMUSonarFromJSON(\n",
    "    f\"{DATAFILES_DIR}/test_split.json\", \n",
    "    label_map=label_map,\n",
    "    target_length=600,\n",
    "    add_noise=False\n",
    ")\n",
    "\n",
    "# Compute global stats on TRAIN ONLY, then share with TEST\n",
    "train_dataset.compute_global_stats()\n",
    "test_dataset.global_mean = train_dataset.global_mean.clone()\n",
    "test_dataset.global_std  = train_dataset.global_std.clone()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=0, drop_last=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=0, drop_last=False)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "# Get sample to determine feature dimensions\n",
    "sample_raw, sample_psd, _ = train_dataset[0]\n",
    "num_channels = sample_raw.shape[0]\n",
    "psd_bins = sample_psd.shape[1]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "print(f\"Input dimensions: {num_channels} channels, {psd_bins} PSD bins, {num_engineered_features} engineered features\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "model = SimpleIMUSonarNet(\n",
    "    num_channels=num_channels,\n",
    "    num_classes=num_classes,\n",
    "    psd_bins=psd_bins,\n",
    "    dropout=0.3  # Slightly higher dropout for the larger model\n",
    ").to(device)\n",
    "\n",
    "# ---------------- Train loop ----------------\n",
    "epochs = 50\n",
    "\n",
    "# Compute class weights on training data\n",
    "train_dataset.compute_class_stats()\n",
    "# Use the computed weights in your loss function\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=train_dataset.class_weights.to(device), \n",
    "    label_smoothing=0.05\n",
    ")\n",
    "#criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # Reduced weight decay\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0.0\n",
    "patience = 5\n",
    "no_improve_epochs = 0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    epoch_start = time()\n",
    "    \n",
    "    for raw_batch, psd_batch, labels in train_loader:\n",
    "        raw_batch = raw_batch.to(device)\n",
    "        psd_batch = psd_batch.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(raw_batch, psd_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in test_loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total   += labels.size(0)\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc  = correct / total\n",
    "    val_loss   = val_loss / len(test_loader)\n",
    "    val_acc    = val_correct / val_total\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - {time() - epoch_start:.1f}s | \" \\\n",
    "            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \" \\\n",
    "            f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # # Early stopping\n",
    "    # if val_acc > best_val_acc:\n",
    "    #     best_val_acc = val_acc\n",
    "    #     no_improve_epochs = 0\n",
    "    #     best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "    # else:\n",
    "    #     no_improve_epochs += 1\n",
    "    #     if no_improve_epochs >= patience:\n",
    "    #         print(f\"⏹ Early stopping at epoch {epoch+1} (best val acc {best_val_acc:.4f})\")\n",
    "    #         break\n",
    "\n",
    "# # Restore best model\n",
    "# if best_state is not None:\n",
    "#     model.load_state_dict(best_state)\n",
    "\n",
    "# ---------------- Final evaluation ----------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            total_loss += criterion(outputs, labels).item() * raw_batch.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "train_loss, train_acc = evaluate(model, train_loader)\n",
    "test_loss,  test_acc  = evaluate(model, test_loader)\n",
    "\n",
    "print('Final Results:')\n",
    "print(f'Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}')\n",
    "print(f'Test loss: {test_loss:.4f}, accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7d594e8b-73b7-495c-b7a5-348f321a8fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PER-CLASS PERFORMANCE ===\n",
      "7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 7, does not match size of target_names, 9. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[224]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m#return all_preds, all_labels\u001b[39;00m\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[32m     41\u001b[39m class_names = [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mClass_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m9\u001b[39m)]  \u001b[38;5;66;03m# Only your 7 actual classes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m analyze_class_performance(model, train_loader, class_names)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[224]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36manalyze_class_performance\u001b[39m\u001b[34m(model, loader, class_names)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== PER-CLASS PERFORMANCE ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(np.unique(all_labels)))\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(all_labels, all_preds, target_names=class_names, digits=\u001b[32m4\u001b[39m))\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[32m     29\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/CS481-env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/CS481-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2693\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2687\u001b[39m         warnings.warn(\n\u001b[32m   2688\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2689\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[32m   2690\u001b[39m             )\n\u001b[32m   2691\u001b[39m         )\n\u001b[32m   2692\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2693\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2694\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2695\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m. Try specifying the labels \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2696\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[32m   2697\u001b[39m         )\n\u001b[32m   2698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2699\u001b[39m     target_names = [\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[31mValueError\u001b[39m: Number of classes, 7, does not match size of target_names, 9. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_class_performance(model, loader, class_names):\n",
    "    \"\"\"Analyze performance per class to see where the issues are\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"=== PER-CLASS PERFORMANCE ===\")\n",
    "    print(len(np.unique(all_labels)))\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    #return all_preds, all_labels\n",
    "\n",
    "# Run the analysis\n",
    "class_names = [f'Class_{i}' for i in range(9)]  # Only your 7 actual classes\n",
    "analyze_class_performance(model, test_loader, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "02abe5f0-f8df-41a9-83da-d1b350ff6618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realistic class analysis:\n",
      "Class 0: 14/21 = 0.667\n",
      "Class 3: 21/25 = 0.840\n",
      "Class 4: 10/21 = 0.476\n",
      "Class 5: 18/19 = 0.947\n",
      "Class 6: 14/16 = 0.875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'correct': 14, 'total': 21},\n",
       " 3: {'correct': 21, 'total': 25},\n",
       " 4: {'correct': 10, 'total': 21},\n",
       " 5: {'correct': 18, 'total': 19},\n",
       " 6: {'correct': 14, 'total': 16}}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only analyze classes that actually have data\n",
    "def realistic_class_analysis(model, loader):\n",
    "    model.eval()\n",
    "    # Only track classes that exist: 0, 3, 4, 5, 6\n",
    "    class_stats = {0: {'correct': 0, 'total': 0},\n",
    "                   3: {'correct': 0, 'total': 0}, \n",
    "                   4: {'correct': 0, 'total': 0},\n",
    "                   5: {'correct': 0, 'total': 0},\n",
    "                   6: {'correct': 0, 'total': 0}}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            \n",
    "            for i in range(len(labels_cpu)):\n",
    "                label = labels_cpu[i]\n",
    "                if label in class_stats:\n",
    "                    class_stats[label]['total'] += 1\n",
    "                    if preds_cpu[i] == label:\n",
    "                        class_stats[label]['correct'] += 1\n",
    "    \n",
    "    print(\"Realistic class analysis:\")\n",
    "    for class_label, stats in class_stats.items():\n",
    "        if stats['total'] > 0:\n",
    "            accuracy = stats['correct'] / stats['total']\n",
    "            print(f\"Class {class_label}: {stats['correct']}/{stats['total']} = {accuracy:.3f}\")\n",
    "    \n",
    "    return class_stats\n",
    "\n",
    "realistic_class_analysis(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4e0b6923-11ae-48b9-bea1-7634d73421a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual class analysis:\n",
      "Class 0: 14/21 = 0.667\n",
      "Class 1: 0/0 = 0.000\n",
      "Class 2: 0/0 = 0.000\n",
      "Class 3: 21/25 = 0.840\n",
      "Class 4: 10/21 = 0.476\n",
      "Class 5: 18/19 = 0.947\n",
      "Class 6: 14/16 = 0.875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([14, 0, 0, 21, 10, 18, 14], [21, 0, 0, 25, 21, 19, 16])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_class_analysis(model, loader):\n",
    "    model.eval()\n",
    "    class_correct = [0] * 7\n",
    "    class_total = [0] * 7\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            # Convert to CPU\n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            \n",
    "            for i in range(len(labels_cpu)):\n",
    "                label = labels_cpu[i]\n",
    "                if label < 7:  # Only your 7 actual classes\n",
    "                    class_total[label] += 1\n",
    "                    if preds_cpu[i] == label:\n",
    "                        class_correct[label] += 1\n",
    "    \n",
    "    print(\"Manual class analysis:\")\n",
    "    for i in range(7):\n",
    "        accuracy = class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        print(f\"Class {i}: {class_correct[i]}/{class_total[i]} = {accuracy:.3f}\")\n",
    "    \n",
    "    return class_correct, class_total\n",
    "\n",
    "manual_class_analysis(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "894fe5a0-e4f3-447f-9b5e-722f1536ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST DATASET ANALYSIS ===\n",
      "Unique labels in test data: [0, 3, 4, 5, 6, 7, 8]\n",
      "Label distribution in test set:\n",
      "Label 0: 21 samples\n",
      "Label 3: 25 samples\n",
      "Label 4: 21 samples\n",
      "Label 5: 19 samples\n",
      "Label 6: 16 samples\n",
      "Label 7: 9 samples\n",
      "Label 8: 10 samples\n",
      "=== TRAIN DATASET ANALYSIS ===\n",
      "Unique labels in train data: [0, 3, 4, 5, 6, 7, 8]\n",
      "Label distribution in test set:\n",
      "Label 0: 81 samples\n",
      "Label 3: 80 samples\n",
      "Label 4: 64 samples\n",
      "Label 5: 64 samples\n",
      "Label 6: 52 samples\n",
      "Label 7: 32 samples\n",
      "Label 8: 35 samples\n"
     ]
    }
   ],
   "source": [
    "# Check what's REALLY in your test dataset\n",
    "print(\"=== TEST DATASET ANALYSIS ===\")\n",
    "test_labels = [item['label'] for item in test_dataset.samples]\n",
    "unique_test_labels = sorted(set(test_labels))\n",
    "print(f\"Unique labels in test data: {unique_test_labels}\")\n",
    "\n",
    "label_counts = {}\n",
    "for label in test_labels:\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "print(\"Label distribution in test set:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "    # Check what's REALLY in your test dataset\n",
    "print(\"=== TRAIN DATASET ANALYSIS ===\")\n",
    "train_labels = [item['label'] for item in train_dataset.samples]\n",
    "unique_train_labels = sorted(set(train_labels))\n",
    "print(f\"Unique labels in train data: {unique_train_labels}\")\n",
    "\n",
    "label_counts = {}\n",
    "for label in train_labels:\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "print(\"Label distribution in test set:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    print(f\"Label {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "475eb277-4447-408e-90fe-6dd8c52f0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE class analysis:\n",
      "Class 0: 14/21 = 0.667\n",
      "Class 3: 21/25 = 0.840\n",
      "Class 4: 10/21 = 0.476\n",
      "Class 5: 18/19 = 0.947\n",
      "Class 6: 14/16 = 0.875\n",
      "Class 7: 8/9 = 0.889\n",
      "Class 8: 7/10 = 0.700\n"
     ]
    }
   ],
   "source": [
    "def complete_class_analysis(model, loader):\n",
    "    \"\"\"Analyze ALL classes including 7 and 8\"\"\"\n",
    "    model.eval()\n",
    "    # Track all 7 classes that exist in your data\n",
    "    class_stats = {0: {'correct': 0, 'total': 0},\n",
    "                   3: {'correct': 0, 'total': 0},\n",
    "                   4: {'correct': 0, 'total': 0},\n",
    "                   5: {'correct': 0, 'total': 0},\n",
    "                   6: {'correct': 0, 'total': 0},\n",
    "                   7: {'correct': 0, 'total': 0},\n",
    "                   8: {'correct': 0, 'total': 0}}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            \n",
    "            for i in range(len(labels_cpu)):\n",
    "                label = labels_cpu[i]\n",
    "                if label in class_stats:\n",
    "                    class_stats[label]['total'] += 1\n",
    "                    if preds_cpu[i] == label:\n",
    "                        class_stats[label]['correct'] += 1\n",
    "    \n",
    "    print(\"COMPLETE class analysis:\")\n",
    "    for class_label in sorted(class_stats.keys()):\n",
    "        stats = class_stats[class_label]\n",
    "        if stats['total'] > 0:\n",
    "            accuracy = stats['correct'] / stats['total']\n",
    "            print(f\"Class {class_label}: {stats['correct']}/{stats['total']} = {accuracy:.3f}\")\n",
    "        else:\n",
    "            print(f\"Class {class_label}: 0/0 = N/A\")\n",
    "    \n",
    "    return class_stats\n",
    "\n",
    "# Run the complete analysis\n",
    "complete_stats = complete_class_analysis(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "123de336-c0c4-443d-9d5d-592e29b2df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4 confusion:\n",
      "  Class 4 → Class 8: 3 times\n",
      "  Class 4 → Class 3: 3 times\n",
      "  Class 4 → Class 0: 2 times\n",
      "  Class 4 → Class 7: 2 times\n",
      "  Class 4 → Class 5: 1 times\n",
      "Class 0 confusion:\n",
      "  Class 0 → Class 4: 2 times\n",
      "  Class 0 → Class 8: 2 times\n",
      "  Class 0 → Class 7: 2 times\n",
      "  Class 0 → Class 3: 1 times\n"
     ]
    }
   ],
   "source": [
    "def analyze_problem_classes(model, loader):\n",
    "    \"\"\"Analyze Class 4 and Class 0 errors in detail\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            preds_cpu = preds.cpu().numpy()\n",
    "            \n",
    "            for i in range(len(labels_cpu)):\n",
    "                label = labels_cpu[i]\n",
    "                if label in [0, 4] and preds_cpu[i] != label:  # Only problem classes\n",
    "                    errors.append({\n",
    "                        'true': label,\n",
    "                        'predicted': preds_cpu[i],\n",
    "                        'confidence': F.softmax(outputs[i], dim=0)[preds[i]].item()\n",
    "                    })\n",
    "    \n",
    "    # Analyze confusion patterns\n",
    "    from collections import Counter\n",
    "    print(\"Class 4 confusion:\")\n",
    "    class_4_errors = [e for e in errors if e['true'] == 4]\n",
    "    confusion_4 = Counter([e['predicted'] for e in class_4_errors])\n",
    "    for pred, count in confusion_4.most_common():\n",
    "        print(f\"  Class 4 → Class {pred}: {count} times\")\n",
    "    \n",
    "    print(\"Class 0 confusion:\")  \n",
    "    class_0_errors = [e for e in errors if e['true'] == 0]\n",
    "    confusion_0 = Counter([e['predicted'] for e in class_0_errors])\n",
    "    for pred, count in confusion_0.most_common():\n",
    "        print(f\"  Class 0 → Class {pred}: {count} times\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "problem_errors = analyze_problem_classes(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5b00f0ff-d38f-438e-8de2-5f40476694e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE CLASS PERFORMANCE (9 classes) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_0     0.8235    0.6667    0.7368        21\n",
      "     Class_3     0.7778    0.8400    0.8077        25\n",
      "     Class_4     0.7143    0.4762    0.5714        21\n",
      "     Class_5     0.8182    0.9474    0.8780        19\n",
      "     Class_6     1.0000    0.8750    0.9333        16\n",
      "     Class_7     0.5714    0.8889    0.6957         9\n",
      "     Class_8     0.5385    0.7000    0.6087        10\n",
      "\n",
      "    accuracy                         0.7603       121\n",
      "   macro avg     0.7491    0.7706    0.7474       121\n",
      "weighted avg     0.7753    0.7603    0.7573       121\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_complete_class_performance(model, loader, all_classes=[0, 3, 4, 5, 6, 7, 8]):\n",
    "    \"\"\"Analyze performance for ALL classes the model outputs\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Use ALL classes that the model can predict (9 classes)\n",
    "    # not just the ones that appear in this particular batch\n",
    "    class_names = [f'Class_{i}' for i in all_classes]\n",
    "    \n",
    "    print(\"=== COMPLETE CLASS PERFORMANCE (9 classes) ===\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                               labels=all_classes,  # Force include all 9 classes\n",
    "                               target_names=class_names, \n",
    "                               digits=4,\n",
    "                               zero_division=0))  # Handle classes with no samples\n",
    "    \n",
    "    # Confusion matrix for all classes\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=all_classes)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix (All 9 Classes)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # return all_preds, all_labels\n",
    "\n",
    "# Run the complete analysis with ALL 9 classes\n",
    "all_classes = [0, 3, 4, 5, 6, 7, 8]  # Your actual class labels\n",
    "analyze_complete_class_performance(model, test_loader, all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5edfdb9e-e1f4-42f8-b0be-7b619589c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([32, 9])\n",
      "Number of classes: 9\n",
      "Unique predictions: [0, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Verify the model is actually outputting 9 classes\n",
    "def verify_model_output(model, loader):\n",
    "    \"\"\"Check that model outputs predictions for all 9 classes\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for raw_batch, psd_batch, labels in loader:\n",
    "            raw_batch = raw_batch.to(device)\n",
    "            psd_batch = psd_batch.to(device)\n",
    "            \n",
    "            outputs = model(raw_batch, psd_batch)\n",
    "            \n",
    "            print(f\"Model output shape: {outputs.shape}\")  # Should be (batch_size, 9)\n",
    "            print(f\"Number of classes: {outputs.shape[1]}\")\n",
    "            \n",
    "            # Check if model can predict all 9 classes\n",
    "            _, preds = outputs.max(1)\n",
    "            unique_preds = sorted(torch.unique(preds).cpu().numpy())\n",
    "            print(f\"Unique predictions: {unique_preds}\")\n",
    "            \n",
    "            break  # Just check first batch\n",
    "\n",
    "verify_model_output(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5fc4c-6da2-414c-8af6-c0fbe6ba53ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddf2a5d-e03a-4d26-b6e0-62d313e1b0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
